aed2f5226349c3947f5e66c1362087fc06caaa6c 2025-04-22T11:45:57-04:00---
 LICENSE | 21 +++++++++++++++++++++
 1 file changed, 21 insertions(+)

diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..c2aaf3a
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,21 @@
+MIT License
+
+Copyright (c) 2025 Joseph Courtney
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.

81a6d3831e0893641abfadb9a7e867fc3648fad6 2025-04-22T11:47:02-04:00---
 .gitignore                 | 734 +++++++++++++++++++++++++++++++++++++++++++++
 .grobl.config.json         |  26 ++
 README.md                  |  22 ++
 pyproject.toml             | 112 +++++++
 ruff.default.toml          |   1 +
 src/showcov/__init__.py    |   0
 src/showcov/__version__.py |   1 +
 src/showcov/main.py        | 259 ++++++++++++++++
 tests/__init__.py          |   0
 tests/test_main.py         | 380 +++++++++++++++++++++++
 10 files changed, 1535 insertions(+)

diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..2619be4
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,734 @@
+## macos
+# General
+.DS_Store
+.AppleDouble
+.LSOverride
+
+# Icon must end with two \r
+Icon
+
+# Thumbnails
+._*
+
+# Files that might appear in the root of a volume
+.DocumentRevisions-V100
+.fseventsd
+.Spotlight-V100
+.TemporaryItems
+.Trashes
+.VolumeIcon.icns
+.com.apple.timemachine.donotpresent
+
+# Directories potentially created on remote AFP share
+.AppleDB
+.AppleDesktop
+Network Trash Folder
+Temporary Items
+.apdisk
+
+
+## Linux
+*~
+
+# temporary files which can be created if a process still has a handle open of a deleted file
+.fuse_hidden*
+
+# KDE directory preferences
+.directory
+
+# Linux trash folder which might appear on any partition or disk
+.Trash-*
+
+# .nfs files are created when an open file is removed but is still being accessed
+.nfs*
+
+
+## Windows
+# Windows thumbnail cache files
+Thumbs.db
+Thumbs.db:encryptable
+ehthumbs.db
+ehthumbs_vista.db
+
+# Dump file
+*.stackdump
+
+# Folder config file
+[Dd]esktop.ini
+
+# Recycle Bin used on file shares
+$RECYCLE.BIN/
+
+# Windows Installer files
+*.cab
+*.msi
+*.msix
+*.msm
+*.msp
+
+# Windows shortcuts
+*.lnk
+
+
+### Common build tool outputs
+#target/
+#build/
+#dist/
+
+
+## Python
+# Python-generated files
+__pycache__/
+*.py[oc]
+*.egg-info
+
+# Virtual environments
+.venv
+.env
+env/
+venv/
+ENV/
+env.bak/
+venv.bak/
+
+# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
+__pypackages__/
+
+# PyPI configuration file
+.pypirc
+
+# linting / type checking / testing reports
+.coverage
+cov.xml
+coverage.xml
+.pytest_cache/
+.mypy_cache
+.dmypy.json
+dmypy.json
+htmlcov/
+.tox/
+.nox/
+.cache
+nosetests.xml
+*.cover
+*.py,cover
+.hypothesis/
+cover/
+
+
+
+# uv
+.python-version
+uv.lock
+
+
+# Distribution / packaging
+.Python
+develop-eggs/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+share/python-wheels/
+*.egg-info/
+.installed.cfg
+*.egg
+MANIFEST
+
+# PyInstaller
+#  Usually these files are written by a python script from a template
+#  before PyInstaller builds the exe, so as to inject date/other infos into it.
+*.manifest
+*.spec
+
+# Installer logs
+pip-log.txt
+pip-delete-this-directory.txt
+
+# Translations
+*.mo
+*.pot
+
+# Django stuff:
+*.log
+local_settings.py
+# db.sqlite3
+db.sqlite3-journal
+
+# Flask stuff:
+instance/
+.webassets-cache
+
+# Scrapy stuff:
+.scrapy
+
+# Sphinx documentation
+docs/_build/
+
+# PyBuilder
+.pybuilder/
+
+# Jupyter Notebook
+.ipynb_checkpoints
+
+# IPython
+profile_default/
+ipython_config.py
+
+# Celery stuff
+celerybeat-schedule
+celerybeat.pid
+
+# SageMath parsed files
+*.sage.py
+
+# Spyder project settings
+.spyderproject
+.spyproject
+
+# Rope project settings
+.ropeproject
+
+# mkdocs documentation
+/site
+
+# Pyre type checker
+.pyre/
+
+# pytype static type analyzer
+.pytype/
+
+# Cython debug symbols
+cython_debug/
+
+
+### C / C++
+## Prerequisites
+#*.d
+#
+## Object files
+#*.o
+#*.ko
+#*.obj
+#*.elf
+#
+## Executables
+#*.exe
+## *.out
+#*.app
+#*.i*86
+#*.x86_64
+#*.hex
+#
+## Shared objects (inc. Windows DLLs)
+#*.dll
+#*.so.*
+#*.dylib
+#
+## Precompiled Headers
+#*.gch
+#*.pch
+#
+## Libraries
+#*.lib
+#*.a
+#*.la
+#*.lo
+
+
+### C
+## Linker output
+#*.ilk
+#*.map
+#*.exp
+#
+## Debug files
+#*.dSYM/
+#*.su
+#*.idb
+#*.pdb
+#
+## Kernel Module Compile Results
+#*.mod*
+#*.cmd
+#.tmp_versions/
+#modules.order
+#Module.symvers
+#Mkfile.old
+#dkms.conf
+
+
+### C++
+#
+## Compiled Object files
+#*.slo
+#*.lo
+#
+#
+## Fortran module files
+#*.mod
+#*.smod
+#
+## Compiled Static libraries
+#*.lai
+#*.la
+#*.a
+#*.lib
+
+
+### CMake
+#CMakeLists.txt.user
+#CMakeCache.txt
+#CMakeFiles
+#CMakeScripts
+#Testing
+#Makefile
+#cmake_install.cmake
+#install_manifest.txt
+#compile_commands.json
+#CTestTestfile.cmake
+#_deps
+#CMakeUserPresets.json
+
+
+### CUDA
+#*.i
+#*.ii
+#*.gpu
+#*.ptx
+#*.cubin
+#*.fatbin
+
+
+### Java
+## Compiled class file
+#*.class
+#
+## Log file
+#*.log
+#
+## BlueJ files
+#*.ctxt
+#
+## Mobile Tools for Java (J2ME)
+#.mtj.tmp/
+#
+## Package Files #
+#*.jar
+#*.war
+#*.nar
+#*.ear
+#*.zip
+#*.tar.gz
+#*.rar
+#
+## virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml
+#hs_err_pid*
+#replay_pid*
+
+
+### Gradle
+#.gradle
+#**/build/
+#!src/**/build/
+#
+## Ignore Gradle GUI config
+#gradle-app.setting
+#
+## Avoid ignoring Gradle wrapper jar file (.jar files are usually ignored)
+#!gradle-wrapper.jar
+#
+## Avoid ignore Gradle wrappper properties
+#!gradle-wrapper.properties
+#
+## Cache of project
+#.gradletasknamecache
+#
+## Eclipse Gradle plugin generated files
+## Eclipse Core
+#.project
+## JDT-specific (Eclipse Java Development Tools)
+#.classpath
+#
+## Lua
+## Compiled Lua sources
+#luac.out
+#
+## luarocks build files
+#*.src.rock
+#
+## Object files
+#*.os
+#
+## Precompiled Headers
+#*.gch
+#*.pch
+#
+## Libraries
+#*.def
+
+
+### Xcode
+## Add this line if you want to avoid checking in source code from the Xcode workspace
+#*.xcodeproj
+#*.xcworkspace
+#
+## Playgrounds
+#timeline.xctimeline
+#playground.xcworkspace
+#
+## User settings
+#xcuserdata/
+#
+## App packaging
+#*.ipa
+#*.dSYM.zip
+#*.dSYM
+
+
+### Objective-C / Swift
+#*.hmap
+## Carthage
+##
+## Add this line if you want to avoid checking in source code from Carthage dependencies.
+## Carthage/Checkouts
+#
+#Carthage/Build/
+#
+## fastlane
+##
+## It is recommended to not store the screenshots in the git repo.
+## Instead, use fastlane to re-generate the screenshots whenever they are needed.
+## For more information about the recommended setup visit:
+## https://docs.fastlane.tools/best-practices/source-control/#source-control
+#
+#fastlane/report.xml
+#fastlane/Preview.html
+#fastlane/screenshots/**/*.png
+#fastlane/test_output
+
+
+
+
+### Swift
+## Swift Package Manager
+##
+## Add this line if you want to avoid checking in source code from Swift Package Manager dependencies.
+#Packages/
+#Package.pins
+#Package.resolved
+#.swiftpm
+#
+#.build/
+
+
+### Rust
+## Generated by Cargo
+## will have compiled files and executables
+#debug/
+#
+## These are backup files generated by rustfmt
+#**/*.rs.bk
+
+
+### Tex
+## Core latex/pdflatex auxiliary files:
+#*.aux
+#*.lof
+#*.log
+#*.lot
+#*.fls
+#*.out
+#*.toc
+#*.fmt
+#*.fot
+#*.cb
+#*.cb2
+#.*.lb
+#
+## Intermediate documents:
+#*.dvi
+#*.xdv
+#*-converted-to.*
+#
+## Bibliography auxiliary files (bibtex/biblatex/biber):
+#*.bbl
+#*.bbl-SAVE-ERROR
+#*.bcf
+#*.blg
+#*-blx.aux
+#*-blx.bib
+#*.run.xml
+#
+## Build tool auxiliary files:
+#*.fdb_latexmk
+#*.synctex
+#*.synctex(busy)
+#*.synctex.gz
+#*.synctex.gz(busy)
+#*.pdfsync
+#*.rubbercache
+#rubber.cache
+#
+## Build tool directories for auxiliary files
+## latexrun
+#latex.out/
+#
+## Auxiliary and intermediate files from other packages:
+## algorithms
+#*.alg
+#*.loa
+#
+## achemso
+#acs-*.bib
+#
+## amsthm
+#*.thm
+#
+## beamer
+#*.nav
+#*.pre
+#*.snm
+#*.vrb
+#
+## changes
+#*.soc
+#
+## comment
+#*.cut
+#
+## cprotect
+#*.cpt
+#
+## elsarticle (documentclass of Elsevier journals)
+#*.spl
+#
+## endnotes
+#*.ent
+#
+## fixme
+#*.lox
+#
+## feynmf/feynmp
+#*.mf
+#*.mp
+#*.t[1-9]
+#*.t[1-9][0-9]
+#*.tfm
+#
+##(r)(e)ledmac/(r)(e)ledpar
+#*.end
+#*.?end
+#*.[1-9]
+#*.[1-9][0-9]
+#*.[1-9][0-9][0-9]
+#*.[1-9]R
+#*.[1-9][0-9]R
+#*.[1-9][0-9][0-9]R
+#*.eledsec[1-9]
+#*.eledsec[1-9]R
+#*.eledsec[1-9][0-9]
+#*.eledsec[1-9][0-9]R
+#*.eledsec[1-9][0-9][0-9]
+#*.eledsec[1-9][0-9][0-9]R
+#
+## glossaries
+#*.acn
+#*.acr
+#*.glg
+#*.glo
+#*.gls
+#*.glsdefs
+#*.lzo
+#*.lzs
+#*.slg
+#*.slo
+#*.sls
+#
+## gnuplot
+#*.gnuplot
+#*.table
+#
+## gnuplottex
+#*-gnuplottex-*
+#
+## gregoriotex
+#*.gaux
+#*.glog
+#*.gtex
+#
+## htlatex
+#*.4ct
+#*.4tc
+#*.idv
+#*.lg
+#*.trc
+#*.xref
+#
+## hypdoc
+#*.hd
+#
+## hyperref
+#*.brf
+#
+## knitr
+#*-concordance.tex
+#*-tikzDictionary
+#
+## listings
+#*.lol
+#
+## luatexja-ruby
+#*.ltjruby
+#
+## makeidx
+#*.idx
+#*.ilg
+#*.ind
+#
+## minitoc
+#*.maf
+#*.mlf
+#*.mlt
+#*.mtc[0-9]*
+#*.slf[0-9]*
+#*.slt[0-9]*
+#*.stc[0-9]*
+#
+## minted
+#_minted*
+#*.pyg
+#
+## morewrites
+#*.mw
+#
+## newpax
+#*.newpax
+#
+## nomencl
+#*.nlg
+#*.nlo
+#*.nls
+#
+## pax
+#*.pax
+#
+## pdfpcnotes
+#*.pdfpc
+#
+## sagetex
+#*.sagetex.sage
+#*.sagetex.py
+#*.sagetex.scmd
+#
+## scrwfile
+#*.wrt
+#
+## svg
+#svg-inkscape/
+#
+## sympy
+#*.sout
+#*.sympy
+#sympy-plots-for-*.tex/
+#
+## pdfcomment
+#*.upa
+#*.upb
+#
+## pythontex
+#*.pytxcode
+#pythontex-files-*/
+#
+## tcolorbox
+#*.listing
+#
+## thmtools
+#*.loe
+#
+## TikZ & PGF
+#*.dpth
+#*.md5
+#*.auxlock
+#
+## titletoc
+#*.ptc
+#
+## todonotes
+#*.tdo
+#
+## vhistory
+#*.hst
+#*.ver
+#
+## easy-todo
+#*.lod
+#
+## xcolor
+#*.xcp
+#
+## xmpincl
+#*.xmpi
+#
+## xindy
+#*.xdy
+#
+## xypic precompiled matrices and outlines
+#*.xyc
+#*.xyd
+#
+## endfloat
+#*.ttt
+#*.fff
+#
+## Latexian
+#TSWLatexianTemp*
+#
+## Editors:
+## WinEdt
+#*.bak
+#*.sav
+#
+## Texpad
+#.texpadtmp
+#
+## LyX
+#*.lyx~
+#
+## Kile
+#*.backup
+#
+## gummi
+#.*.swp
+#
+## KBibTeX
+#*~[0-9]*
+#
+## TeXnicCenter
+#*.tps
+#
+## auto folder when using emacs and auctex
+#./auto/*
+#*.el
+#
+## expex forward references with \gathertags
+#*-tags.tex
+#
+## standalone packages
+#*.sta
+#
+## Makeindex log files
+#*.lpz
+#
+## xwatermark package
+#*.xwm
+#
+## REVTeX puts footnotes in the bibliography by default, unless the nofootinbib
+## option is specified. Footnotes are the stored in a file with suffix Notes.bib.
+## Uncomment the next line to have this generated file ignored.
+#*Notes.bib
diff --git a/.grobl.config.json b/.grobl.config.json
new file mode 100644
index 0000000..14b44fc
--- /dev/null
+++ b/.grobl.config.json
@@ -0,0 +1,26 @@
+{
+  "exclude_tree": [
+    "*.egg-info",
+    "*.ipynb",
+    ".git/",
+    ".gitignore",
+    ".gitmodules",
+    ".groblignore",
+    ".pytest_cache/",
+    ".python-version",
+    ".venv/",
+    "CODE_OF_CONDUCT.md",
+    "CONTRIBUTING.md",
+    "LICENSE",
+    ".coverage.xml",
+    "ruff.default.toml",
+    "uv.lock",
+    "yarn.lock"
+  ],
+  "exclude_print": [
+    "*.json",
+    "*.html"
+  ],
+  "include_tree_tags": "tree",
+  "include_file_tags": "file"
+}
diff --git a/README.md b/README.md
new file mode 100644
index 0000000..41867e4
--- /dev/null
+++ b/README.md
@@ -0,0 +1,22 @@
+# showcov
+
+showcov is a command-line utility that prints uncovered lines of code—grouped into contiguous sections—from a coverage XML report.
+
+## Installation
+
+```bash
+uv tool install clone https://github.com/josephcourtney/showcov.git
+```
+
+## Usage
+
+```bash
+showcov [COVERAGE_XML_FILE]
+```
+
+- **COVERAGE_XML_FILE**: _(Optional)_ The path to your coverage XML report.  
+  If omitted, showcov will search for a configuration file (such as `pyproject.toml`, `.coveragerc`, or `setup.cfg`) that specifies the XML report’s location.
+
+## License
+
+This project is licensed under the [MIT License](LICENSE).
diff --git a/pyproject.toml b/pyproject.toml
new file mode 100644
index 0000000..12a98eb
--- /dev/null
+++ b/pyproject.toml
@@ -0,0 +1,112 @@
+# =================================== project ====================================
+[project]
+  name = "showcov"
+  dynamic = ["version"]
+  description = "Print out uncovered code."
+  readme = "README.md"
+  authors = [
+    { name = "Joseph M. Courtney", email = "joseph.m.courtney@gmail.com" },
+  ]
+  urls = { "Homepage" = "https://github.com/josephcourtney/showcov", "Bug Tracker" = "https://github.com/josephcourtney/showcov/issues" }
+  license = { text = "MIT License" }
+  classifiers = [
+    "Development Status :: 3 - Alpha",
+    "License :: OSI Approved :: MIT License",
+    "Programming Language :: Python :: 3",
+    "Operating System :: OS Independent",
+  ]
+  requires-python = ">=3.12"
+  dependencies = [
+    "colorama>=0.4.6",
+    "configparser>=7.1.0",
+    "defusedxml>=0.7.1",
+  ]
+
+  [project.scripts]
+    showcov = "showcov.main:main"
+
+[dependency-groups]
+  dev = [
+    "basedpyright>=1.28.1",
+    "coverage>=7.6.10",
+    "pytest-cov>=6.0.0",
+    "pytest-randomly>=3.16.0",
+    "pytest>=8.3.5",
+    "ruff>=0.9.4",
+    "types-colorama>=0.4.15.20240311",
+    "types-defusedxml>=0.7.0.20240218",
+    "types-toml>=0.10.8.20240310",
+  ]
+
+# =================================== build ====================================
+[build-system]
+  requires      = ["hatchling"]
+  build-backend = "hatchling.build"
+
+
+[tool.hatch.build]
+  includes = ["src/showcov/**"]
+
+[tool.hatch.version]
+  path = "src/showcov/__version__.py"
+
+# ==================================== lint ====================================
+[tool.ruff]
+  extend = "./ruff.default.toml"
+
+  [tool.ruff.lint]
+    ignore = []
+
+# =================================== typecheck ===================================
+[tool.basedpyright]
+  typeCheckingMode = "recommended"
+  pythonVersion = "3.13"
+  pythonPlatform = "Darwin"
+  reportImplicitOverride = false
+  reportMissingTypeStubs = false
+  reportUnusedParameter = false
+  executionEnvironments = [
+    { root = "tests", reportPrivateUsage = false, reportUnusedCallResult = false, extraPaths = [] },
+  ]
+
+
+  # =================================== test ===================================
+
+[tool.pytest.ini_options]
+  addopts = [
+    "--cov=showcov",
+    "--cov-report=xml",
+    "--cov-report=term-missing",
+  ]
+  testpaths = ["tests"]
+
+# =================================== test:coverage ===================================
+[tool.coverage.run]
+  source   = ["."]
+  branch   = true
+  parallel = true
+
+[tool.coverage.report]
+  show_missing = true
+  skip_covered = true
+  # Regexes for lines to exclude from consideration
+  exclude_also = [
+    # Don't complain about missing debug-only code:
+    "def __repr__",
+    "if self\\.debug",
+
+    # Don't complain if tests don't hit defensive assertion code:
+    "raise AssertionError",
+    "raise NotImplementedError",
+
+    # Don't complain if non-runnable code isn't run:
+    "if 0:",
+    "if __name__ == .__main__.:",
+
+    # Don't complain about abstract methods, they aren't run:
+    "@(abc\\.)?abstractmethod",
+  ]
+  ignore_errors = true
+
+[tool.coverage.xml]
+  output = ".coverage.xml"
diff --git a/ruff.default.toml b/ruff.default.toml
new file mode 120000
index 0000000..5925ff3
--- /dev/null
+++ b/ruff.default.toml
@@ -0,0 +1 @@
+/Users/josephcourtney/.config/ruff/ruff.toml
\ No newline at end of file
diff --git a/src/showcov/__init__.py b/src/showcov/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/src/showcov/__version__.py b/src/showcov/__version__.py
new file mode 100644
index 0000000..a73339b
--- /dev/null
+++ b/src/showcov/__version__.py
@@ -0,0 +1 @@
+__version__ = "0.0.8"
diff --git a/src/showcov/main.py b/src/showcov/main.py
new file mode 100644
index 0000000..a92442b
--- /dev/null
+++ b/src/showcov/main.py
@@ -0,0 +1,259 @@
+"""
+Prints out all uncovered lines (grouped into contiguous sections) from a coverage XML report.
+
+If no XML filename is given as a command-line argument, the script will try to read it from
+a configuration file (pyproject.toml, .coveragerc, or setup.cfg).
+"""
+
+import argparse
+import logging
+import sys
+import tomllib
+from configparser import ConfigParser
+from configparser import Error as ConfigError
+from pathlib import Path
+from typing import TYPE_CHECKING, Optional
+
+from colorama import Fore, Style
+from colorama import init as colorama_init
+from defusedxml import ElementTree
+
+# Initialize colorama
+colorama_init(autoreset=True)
+
+if TYPE_CHECKING:
+    from xml.etree.ElementTree import Element  # noqa: S405
+
+# ANSI color codes (cross-platform)
+RESET = Style.RESET_ALL
+BOLD = Style.BRIGHT
+YELLOW = Fore.YELLOW
+CYAN = Fore.CYAN
+MAGENTA = Fore.MAGENTA
+GREEN = Fore.GREEN
+RED = Fore.RED
+
+# Constants
+CONSECUTIVE_STEP = 1
+
+# Configure logging
+logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
+logger = logging.getLogger(__name__)
+
+
+class CoverageXMLNotFoundError(Exception):
+    """Coverage XML file not found."""
+
+
+def _get_xml_from_config(config_path: Path, section: str, option: str) -> str | None:
+    """Extract an XML path from the configuration file."""
+    config = ConfigParser()
+    try:
+        config.read(config_path)
+    except (OSError, ConfigError, ValueError) as e:
+        logger.warning("Failed to parse %s: %s", config_path, e)
+        return None
+
+    return (
+        config.get(section, option)
+        if config.has_section(section) and config.has_option(section, option)
+        else None
+    )
+
+
+def _get_xml_from_pyproject(pyproject: Path) -> str | None:
+    """Extract the XML coverage file path from pyproject.toml."""
+    try:
+        with pyproject.open("rb") as f:
+            data = tomllib.load(f)
+    except (OSError, tomllib.TOMLDecodeError) as e:
+        logger.warning("Failed to parse %s: %s", pyproject, e)
+        return None
+
+    tool = data.get("tool", {})
+    coverage_cfg = tool.get("coverage", {})
+    return coverage_cfg.get("xml_report") or coverage_cfg.get("xml", {}).get("output")
+
+
+def get_config_xml_file() -> str | None:
+    """Look for an XML filename in configuration files."""
+    config_files = [
+        (Path("./pyproject.toml").resolve(), _get_xml_from_pyproject),
+        (Path("./.coveragerc").resolve(), lambda p: _get_xml_from_config(p, "xml", "output")),
+        (Path("./setup.cfg").resolve(), lambda p: _get_xml_from_config(p, "coverage:xml", "output")),
+    ]
+
+    for path, extractor in config_files:
+        if path.exists():
+            xml_file = extractor(path)
+            if xml_file:
+                logger.info("Using coverage XML file from config: %s", xml_file)
+                return xml_file
+
+    return None
+
+
+def parse_args() -> argparse.Namespace:
+    """Parse command-line arguments."""
+    parser = argparse.ArgumentParser(description="Show uncovered lines from a coverage XML report.")
+    parser.add_argument("xml_file", nargs="?", help="Path to coverage XML file")
+    return parser.parse_args()
+
+
+def determine_xml_file() -> Path:
+    """Determine the coverage XML file path from arguments or config."""
+    args = parse_args()
+    if args.xml_file:
+        return Path(args.xml_file)
+
+    config_xml = get_config_xml_file()
+    if config_xml:
+        return Path(config_xml)
+
+    msg = "No coverage XML file specified or found in configuration."
+    raise CoverageXMLNotFoundError(msg)
+
+
+def group_consecutive_numbers(numbers: list[int]) -> list[list[int]]:
+    """Group consecutive numbers into sublists."""
+    groups: list[list[int]] = []
+    group: list[int] = []
+
+    for num in numbers:
+        if group and num != group[-1] + CONSECUTIVE_STEP:
+            groups.append(group)
+            group = []
+        group.append(num)
+
+    if group:
+        groups.append(group)
+    return groups
+
+
+def merge_blank_gap_groups(groups: list[list[int]], file_lines: list[str]) -> list[list[int]]:
+    """Merge adjacent groups if the gap between them contains only blank lines."""
+    if not groups:
+        return groups
+
+    merged: list[list[int]] = [groups[0]]
+    for grp in groups[1:]:
+        last_grp = merged[-1]
+        gap_start = last_grp[-1] + 1
+        gap_end = grp[0] - 1
+
+        if gap_start <= gap_end and all(not file_lines[i - 1].strip() for i in range(gap_start, gap_end + 1)):
+            merged[-1].extend(grp)
+        else:
+            merged.append(grp)
+
+    return merged
+
+
+def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
+    """Print uncovered sections from files."""
+    for filename, lines in uncovered.items():
+        lines_sorted = sorted(lines)
+        groups = group_consecutive_numbers(lines_sorted)
+        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename}:{RESET}")
+
+        try:
+            with filename.open(encoding="utf-8") as f:
+                file_lines = f.readlines()
+            groups = merge_blank_gap_groups(groups, file_lines)
+        except OSError:
+            logger.exception("Could not open %s", filename)
+            for grp in groups:
+                print(
+                    f"  {CYAN}Lines {grp[0]}-{grp[-1]}{RESET}"
+                    if len(grp) > 1
+                    else f"  {CYAN}Line {grp[0]}{RESET}"
+                )
+            continue
+
+        for grp in groups:
+            header = (
+                f"  {BOLD}{CYAN}Lines {grp[0]}-{grp[-1]}:{RESET}"
+                if len(grp) > 1
+                else f"  {BOLD}{CYAN}Line {grp[0]}:{RESET}"
+            )
+            print(header)
+            for ln in grp:
+                content = (
+                    file_lines[ln - 1].rstrip("\n") if 1 <= ln <= len(file_lines) else "<line not found>"
+                )
+                print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
+            print()
+
+
+def _gather_uncovered_lines(root: "Element") -> dict[Path, list[int]]:
+    """Gather uncovered lines per file from the parsed XML tree."""
+    uncovered: dict[Path, list[int]] = {}
+
+    # Get all source roots from the XML
+    source_elements = root.findall(".//sources/source")
+    source_roots = [Path(src.text).resolve() for src in source_elements if src.text]
+
+    for cls in root.findall(".//class"):
+        filename_str = cls.get("filename")
+        if not filename_str:
+            continue
+
+        # Try resolving with the source root
+        filename = Path(filename_str)
+        resolved_path = next(
+            (src / filename for src in source_roots if (src / filename).exists()),
+            filename,  # fallback to relative path if none match
+        )
+
+        for line in cls.findall("lines/line"):
+            try:
+                hits = int(line.get("hits", "0"))
+                line_no = int(line.get("number", "0"))
+            except (ValueError, TypeError):
+                continue
+
+            if hits == 0:
+                uncovered.setdefault(resolved_path, []).append(line_no)
+
+    return uncovered
+
+
+def parse_large_xml(file_path: Path) -> Optional["Element"]:
+    """Efficiently parse large XML files with iterparse."""
+    context = ElementTree.iterparse(file_path, events=("start", "end"))
+    for event, elem in context:
+        if event == "end" and elem.tag == "coverage":
+            return elem  # Return root element early to save memory
+    return None
+
+
+def main() -> None:
+    """Entry point for the script."""
+    try:
+        xml_file: Path = determine_xml_file()
+    except CoverageXMLNotFoundError:
+        sys.exit(1)
+
+    try:
+        root = parse_large_xml(xml_file)
+        if root is None:
+            logger.error("Failed to parse coverage XML file: %s", xml_file)
+            sys.exit(1)
+    except ElementTree.ParseError:
+        logger.exception("Error parsing XML file %s", xml_file)
+        sys.exit(1)
+    except OSError:
+        logger.exception("Error opening XML file %s", xml_file)
+        sys.exit(1)
+
+    uncovered = _gather_uncovered_lines(root)
+
+    if not uncovered:
+        print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
+        return
+
+    print_uncovered_sections(uncovered)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/tests/__init__.py b/tests/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/tests/test_main.py b/tests/test_main.py
new file mode 100644
index 0000000..3b1c0d9
--- /dev/null
+++ b/tests/test_main.py
@@ -0,0 +1,380 @@
+import logging
+import sys
+import textwrap
+from configparser import ConfigParser
+from pathlib import Path
+
+import pytest
+from _pytest.capture import CaptureFixture
+from _pytest.monkeypatch import MonkeyPatch
+from defusedxml import ElementTree
+
+# Import functions and exceptions from your module.
+from showcov.main import (
+    CoverageXMLNotFoundError,
+    _gather_uncovered_lines,
+    _get_xml_from_config,
+    _get_xml_from_pyproject,
+    determine_xml_file,
+    get_config_xml_file,
+    group_consecutive_numbers,
+    main,
+    merge_blank_gap_groups,
+    parse_args,
+    parse_large_xml,
+    print_uncovered_sections,
+)
+
+# Set logging level to capture output for tests
+logging.basicConfig(level=logging.INFO)
+
+
+# --- Tests for `_get_xml_from_config` ---
+
+
+def test_get_xml_from_config_success(tmp_path: Path) -> None:
+    config_file = tmp_path / "config.ini"
+    config_file.write_text("[section]\noption = value")
+    assert _get_xml_from_config(config_file, "section", "option") == "value"
+
+
+def test_get_xml_from_config_no_section(tmp_path: Path) -> None:
+    config_file = tmp_path / "config.ini"
+    config_file.write_text("[other_section]\noption = value")
+    assert _get_xml_from_config(config_file, "section", "option") is None
+
+
+def test_get_xml_from_config_no_option(tmp_path: Path) -> None:
+    config_file = tmp_path / "config.ini"
+    config_file.write_text("[section]\nother_option = value")
+    assert _get_xml_from_config(config_file, "section", "option") is None
+
+
+# --- Tests for `get_config_xml_file` ---
+
+
+def test_get_config_xml_file_pyproject(monkeypatch: MonkeyPatch, tmp_path: Path) -> None:
+    pyproject = tmp_path / "pyproject.toml"
+    pyproject.write_text("[tool.coverage]\nxml_report = 'coverage.xml'")
+    monkeypatch.chdir(tmp_path)
+    assert get_config_xml_file() == "coverage.xml"
+
+
+# --- Tests for `determine_xml_file` ---
+
+
+def test_determine_xml_file_argument(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "coverage.xml"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    assert determine_xml_file() == Path("coverage.xml")
+
+
+def test_determine_xml_file_from_config(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    monkeypatch.setattr("showcov.main.get_config_xml_file", lambda: "coverage.xml")
+    assert determine_xml_file() == Path("coverage.xml")
+
+
+def test_determine_xml_file_no_args(monkeypatch: MonkeyPatch) -> None:
+    monkeypatch.setattr(sys, "argv", ["prog"])
+    monkeypatch.setattr("showcov.main.get_config_xml_file", lambda: None)
+    with pytest.raises(CoverageXMLNotFoundError, match="No coverage XML file specified"):
+        determine_xml_file()
+
+
+# --- Tests for `parse_args` ---
+
+
+def test_parse_args_no_file(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    args = parse_args()
+    assert args.xml_file is None
+
+
+def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "coverage.xml"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    args = parse_args()
+    assert args.xml_file == "coverage.xml"
+
+
+# --- Tests for `print_uncovered_sections` ---
+
+
+def test_print_uncovered_sections(tmp_path: Path, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("def foo():\n    pass\n\ndef bar():\n    return 42")
+    uncovered = {source_file: [2, 4, 5]}
+    print_uncovered_sections(uncovered)
+    captured = capsys.readouterr().out
+    assert "Uncovered sections in" in captured
+    assert "Line" in captured
+    assert "2" in captured
+    assert "4" in captured
+    assert "5" in captured
+
+
+# --- Tests for `_gather_uncovered_lines` ---
+
+
+def test_gather_uncovered_lines_invalid_hits() -> None:
+    xml_content = textwrap.dedent("""
+    <coverage>
+      <packages>
+        <package>
+          <classes>
+            <class filename="dummy.py">
+              <lines>
+                <line number="1" hits="notanumber"/>
+                <line number="2" hits="0"/>
+              </lines>
+            </class>
+          </classes>
+        </package>
+      </packages>
+    </coverage>
+    """)
+    root = ElementTree.fromstring(xml_content)
+    uncovered = _gather_uncovered_lines(root)
+    assert Path("dummy.py") in uncovered
+    assert uncovered[Path("dummy.py")] == [2]
+
+
+# --- Tests for `parse_large_xml` ---
+
+
+def test_parse_large_xml(tmp_path: Path) -> None:
+    xml_content = textwrap.dedent("""
+    <coverage>
+      <packages>
+        <package>
+          <classes>
+            <class filename="dummy.py">
+              <lines>
+                <line number="3" hits="0"/>
+                <line number="5" hits="0"/>
+              </lines>
+            </class>
+          </classes>
+        </package>
+      </packages>
+    </coverage>
+    """)
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    root = parse_large_xml(xml_file)
+    uncovered = _gather_uncovered_lines(root)
+    assert Path("dummy.py") in uncovered
+    assert uncovered[Path("dummy.py")] == [3, 5]
+
+
+# --- Tests for `main()` ---
+
+
+def test_main_no_uncovered(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture) -> None:
+    xml_content = textwrap.dedent("""
+        <coverage>
+          <packages>
+            <package>
+              <classes>
+                <class filename="dummy.py">
+                  <lines>
+                    <line number="1" hits="1"/>
+                    <line number="2" hits="1"/>
+                  </lines>
+                </class>
+              </classes>
+            </package>
+          </packages>
+        </coverage>
+    """)
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    monkeypatch.setattr(sys, "argv", ["prog", str(xml_file)])
+    main()
+    captured = capsys.readouterr().out
+    assert "No uncovered lines found!" in captured
+
+
+def test_main_with_uncovered(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("def foo():\n    pass\n\ndef bar():\n    return 42")
+    xml_content = f"""
+        <coverage>
+          <packages>
+            <package>
+              <classes>
+                <class filename="{source_file}">
+                  <lines>
+                    <line number="2" hits="0"/>
+                    <line number="4" hits="0"/>
+                    <line number="5" hits="0"/>
+                  </lines>
+                </class>
+              </classes>
+            </package>
+          </packages>
+        </coverage>
+    """
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    monkeypatch.setattr(sys, "argv", ["prog", str(xml_file)])
+    main()
+    captured = capsys.readouterr().out
+    assert "Uncovered sections in" in captured
+    assert "2" in captured
+    assert "4" in captured
+    assert "5" in captured
+
+
+# --- Tests for _get_xml_from_config exception branch (lines 53-55) ---
+
+
+def test_get_xml_from_config_exception(monkeypatch, tmp_path):
+    config_file = tmp_path / "config.ini"
+    config_file.write_text("some invalid content")
+
+    # Force an exception when reading the config file so that the exception branch is taken.
+    def fake_read(self, filenames, encoding=None):  # noqa: ARG001
+        msg = "simulated error"
+        raise OSError(msg)
+
+    monkeypatch.setattr(ConfigParser, "read", fake_read)
+    result = _get_xml_from_config(config_file, "section", "option")
+    assert result is None
+
+
+# --- Tests for _get_xml_from_pyproject exception branch (lines 69-71) ---
+
+
+def test_get_xml_from_pyproject_exception(monkeypatch, tmp_path):
+    pyproject = tmp_path / "pyproject.toml"
+    pyproject.write_text("invalid content")
+
+    # Force an exception during tomllib.load to simulate a failure parsing the pyproject.toml.
+    def fake_tomllib_load(f):  # noqa: ARG001
+        msg = "simulated error"
+        raise OSError(msg)
+
+    monkeypatch.setattr("showcov.main.tomllib.load", fake_tomllib_load)
+    result = _get_xml_from_pyproject(pyproject)
+    assert result is None
+
+
+# --- Test for get_config_xml_file fallback (line 93) ---
+
+
+def test_get_config_xml_file_no_config(monkeypatch, tmp_path):
+    # When no configuration file is present, get_config_xml_file should return None.
+    # Change into an empty temporary directory.
+    monkeypatch.chdir(tmp_path)
+    result = get_config_xml_file()
+    assert result is None
+
+
+# --- Test for group_consecutive_numbers (line 136) ---
+
+
+def test_group_consecutive_numbers():
+    # Provide a list of numbers and verify that they are grouped into consecutive ranges.
+    numbers = [1, 2, 3, 5, 6, 8]
+    groups = group_consecutive_numbers(numbers)
+    assert groups == [[1, 2, 3], [5, 6], [8]]
+
+
+# --- Test for merge_blank_gap_groups branch (line 147) ---
+
+
+def test_merge_blank_gap_groups_no_merge():
+    # Provide two groups separated by a gap that contains non-blank content.
+    #
+    # In this case, the groups should not be merged.
+    groups = [[1, 2], [4, 5]]
+    # Simulate file lines where the gap (line 3) is not blank.
+    file_lines = [
+        "line 1\n",
+        "line 2\n",
+        "non blank line\n",  # line 3 (not blank)
+        "line 4\n",
+        "line 5\n",
+    ]
+    merged = merge_blank_gap_groups(groups, file_lines)
+    assert merged == groups
+
+
+# --- Test for print_uncovered_sections exception branch (lines 163-166, 171) ---
+
+
+def test_print_uncovered_sections_file_open_error(monkeypatch, capsys, tmp_path):
+    fake_file = tmp_path / "nonexistent.py"
+    uncovered = {fake_file: [1, 2]}
+
+    # Simulate an OSError when trying to open a source file. The function should catch the exception,
+    # log the error, and still print the grouped line numbers.
+    def fake_open(*args, **kwargs):  # noqa: ARG001
+        msg = "simulated file open error"
+        raise OSError(msg)
+
+    # Monkey-patch the open() method on the Path object.
+    monkeypatch.setattr(Path, "open", fake_open)
+    print_uncovered_sections(uncovered)
+    captured = capsys.readouterr().out
+    assert "Uncovered sections in" in captured
+    assert "Line" in captured
+
+
+# --- Test for parse_large_xml fallback (line 218) ---
+
+
+def test_parse_large_xml_no_coverage(tmp_path):
+    # Provide an XML file that does not contain a <coverage> element. parse_large_xml should return None.
+    xml_file = tmp_path / "bad.xml"
+    xml_file.write_text("<root></root>")
+    result = parse_large_xml(xml_file)
+    assert result is None
+
+
+# --- Tests for main() error-handling branches ---
+
+
+def test_main_coverage_xml_not_found(monkeypatch):
+    # Force determine_xml_file to throw CoverageXMLNotFoundError and verify that main() calls sys.exit(1).
+    monkeypatch.setattr(
+        "showcov.main.determine_xml_file",
+        lambda: (_ for _ in ()).throw(CoverageXMLNotFoundError("No coverage XML file specified")),
+    )
+    with pytest.raises(SystemExit) as exc_info:
+        main()
+    assert exc_info.value.code == 1
+
+
+def test_main_parse_error(monkeypatch):
+    # Force parse_large_xml to raise an ElementTree.ParseError and verify that main() calls sys.exit(1).
+    fake_path = Path("dummy.xml")
+    monkeypatch.setattr("showcov.main.determine_xml_file", lambda: fake_path)
+
+    def fake_parse_large_xml(_):
+        msg = "simulated parse error"
+        raise ElementTree.ParseError(msg)
+
+    monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
+    with pytest.raises(SystemExit) as exc_info:
+        main()
+    assert exc_info.value.code == 1
+
+
+def test_main_os_error(monkeypatch):
+    # Force parse_large_xml to raise an OSError and verify that main() calls sys.exit(1).
+    fake_path = Path("dummy.xml")
+    monkeypatch.setattr("showcov.main.determine_xml_file", lambda: fake_path)
+
+    def fake_parse_large_xml(_):
+        msg = "simulated OS error"
+        raise OSError(msg)
+
+    monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
+    with pytest.raises(SystemExit) as exc_info:
+        main()
+    assert exc_info.value.code == 1

85cb2f4f568886029a5368e84ed7891156ceee0e 2025-04-22T11:47:02-04:00---
 src/showcov/__version__.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/showcov/__version__.py b/src/showcov/__version__.py
index a73339b..00ec2dc 100644
--- a/src/showcov/__version__.py
+++ b/src/showcov/__version__.py
@@ -1 +1 @@
-__version__ = "0.0.8"
+__version__ = "0.0.9"

7935b0d471d687b2e7517023048eb87fa39f2d7d 2025-04-22T11:48:51-04:00---
 README.md | 25 +++++++++++++++++++++++++
 1 file changed, 25 insertions(+)

diff --git a/README.md b/README.md
index 41867e4..580c635 100644
--- a/README.md
+++ b/README.md
@@ -17,6 +17,31 @@ showcov [COVERAGE_XML_FILE]
 - **COVERAGE_XML_FILE**: _(Optional)_ The path to your coverage XML report.  
   If omitted, showcov will search for a configuration file (such as `pyproject.toml`, `.coveragerc`, or `setup.cfg`) that specifies the XML report’s location.
 
+Result for showcov itself:
+
+```bash
+INFO: Using coverage XML file from config: .coverage.xml
+
+Uncovered sections in /Users/josephcourtney/code/showcov/src/showcov/__version__.py:
+  Line 1:
+       1: __version__ = "0.0.9"
+
+
+Uncovered sections in /Users/josephcourtney/code/showcov/src/showcov/main.py:
+  Line 25:
+      25:     from xml.etree.ElementTree import Element  # noqa: S405
+
+  Line 136:
+     136:         return groups
+
+  Line 199:
+     199:             continue
+
+  Lines 240-241:
+     240:             logger.error("Failed to parse coverage XML file: %s", xml_file)
+     241:             sys.exit(1)
+```
+
 ## License
 
 This project is licensed under the [MIT License](LICENSE).

37cb6017af740d8270bb9e1692d3908c05de0955 2025-04-22T11:50:17-04:00---
 ruff.default.toml | 179 +++++++++++++++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 178 insertions(+), 1 deletion(-)

diff --git a/ruff.default.toml b/ruff.default.toml
deleted file mode 120000
index 5925ff3..0000000
--- a/ruff.default.toml
+++ /dev/null
@@ -1 +0,0 @@
-/Users/josephcourtney/.config/ruff/ruff.toml
\ No newline at end of file
diff --git a/ruff.default.toml b/ruff.default.toml
new file mode 100644
index 0000000..8be596c
--- /dev/null
+++ b/ruff.default.toml
@@ -0,0 +1,178 @@
+exclude = [
+  ".bzr",
+  ".direnv",
+  ".eggs",
+  ".git",
+  ".git-rewrite",
+  ".hg",
+  ".ipynb_checkpoints",
+  ".mypy_cache",
+  ".nox",
+  ".pants.d",
+  ".pyenv",
+  ".pytest_cache",
+  ".pytype",
+  ".ruff_cache",
+  ".svn",
+  ".tox",
+  ".venv",
+  ".vscode",
+  "__pypackages__",
+  "_build",
+  "buck-out",
+  "build",
+  "dist",
+  "node_modules",
+  "site-packages",
+  "venv",
+]
+
+target-version    = "py312"
+line-length       = 110
+indent-width      = 4
+output-format     = "concise"
+show-fixes        = true
+unsafe-fixes      = true
+fix               = true
+force-exclude     = true
+respect-gitignore = true
+
+[lint]
+  preview = true
+
+  select = [
+    "F",     # Pyflakes
+    "E",     # pycodestyle Error
+    "W",     # pycodestyle Warning
+    "C90",   # mccabe
+    "I",     # isort
+    "N",     # pep8-naming
+    "D",     # pydocstyle
+    "UP",    # pyupgrade
+    "YTT",   # flake8-2020
+    "ANN",   # flake8-annotations
+    "ASYNC", # flake8-async
+    "S",     # flake8-bandit
+    "BLE",   # flake8-blind-except
+    "FBT",   # flake8-boolean-trap
+    "B",     # flake8-bugbear
+    "A",     # flake8-builtins
+    "COM",   # flake8-commas
+    "CPY",   # flake8-copyright
+    "C4",    # flake8-comprehensions
+    "DTZ",   # flake8-datetimez
+    "T10",   # flake8-debugger
+    "DJ",    # flake8-django
+    "EM",    # flake8-errmsg
+    "EXE",   # flake8-executable
+    "FA",    # flake8-future-annotations
+    "ISC",   # flake8-implicit-str-concat
+    "ICN",   # flake8-import-conventions
+    "G",     # flake8-logging-format
+    "INP",   # flake8-no-pep420
+    "PIE",   # flake8-pie
+    "T20",   # flake8-print
+    "PYI",   # flake8-pyi
+    "PT",    # flake8-pytest-style
+    "Q",     # flake8-quotes
+    "RSE",   # flake8-raise
+    "RET",   # flake8-return
+    "SLF",   # flake8-self
+    "SLOT",  # flake8-slots
+    "SIM",   # flake8-simplify
+    "TID",   # flake8-tidy-imports
+    "TCH",   # flake8-type-checking
+    "INT",   # flake8-gettext
+    "ARG",   # flake8-unused-arguments
+    "PTH",   # flake8-use-pathlib
+    "TD",    # flake8-todos
+    "FIX",   # flake8-fixme
+    "ERA",   # eradicate
+    "PD",    # pandas-vet
+    "PGH",   # pygrep-hooks
+    "PL",    # Pylint
+    "TRY",   # tryceratops
+    "FLY",   # flynt
+    "NPY",   # NumPy-specific rules
+    "AIR",   # Airflow
+    "PERF",  # Perflint
+    "FURB",  # refurb
+    "LOG",   # flake8-logging
+    "RUF",   # Ruff-specific rules
+  ]
+
+  # for development
+  # ignore when linting
+  ignore = [
+    "ERA001", # Found commented-out code
+    "CPY001", # Missing copyright notice at top of file
+
+    "D100", # Missing docstring in public module
+    "D101", # Missing docstring in public class
+    "D102", # Missing docstring in public method
+    "D103", # Missing docstring in public function
+    "D104", # Missing docstring in public package
+
+    "T201", # `print` found
+
+    "PLR0913", # Too many arguments in function definition
+    "PLR0917", # Too many positional arguments
+
+    # "ANN101", # Missing type annotation for `self` in method
+    # "ANN002", # Missing type annotation for *args
+    # "ANN003", # Missing type annotation for **kwargs
+
+    # conflict with formatting
+    "COM812", # missing trailing comma
+    "ISC001", # implicitly concatenated string literals on one line
+  ]
+
+  [lint.per-file-ignores]
+    "tests/**/*.py" = [
+      "S101",    # Use of `assert` detected
+      "PLR2004", # Magic value used in comparison
+      "SLF001",  # Private member accessed
+      "PLC2701", # Private name import from external module
+      "S404",    # `subprocess` module is possibly insecure
+      "S603",    # `subprocess` call: check for execution of untrusted
+    ]
+
+    # disable autofix when linting
+    unfixable = [
+      "F401", # delete unused imports
+      "F841", # remove assignment to unused variable
+    ]
+
+
+    # # for release
+    # # ignore when linting
+    # ignore = [
+    #     # "CPY001", # Missing copyright notice at top of file
+    #
+    #     "PLR0913", # Too many arguments in function definition
+    #     "PLR0917", # Too many positional arguments
+    #
+    #     # conflict with formatting
+    #     "COM812", # missing trailing comma
+    #     "ISC001", # implicitly concatenated string literals on one line
+    # ]
+    #
+    # # disable autofix when linting
+    # unfixable = []
+
+  [lint.pydocstyle]
+    convention = "numpy"
+
+  [lint.flake8-annotations]
+    ignore-fully-untyped = true
+    allow-star-arg-any   = true
+    mypy-init-return     = true
+
+[format]
+  docstring-code-format      = true      # format code in docstrings
+  docstring-code-line-length = "dynamic"
+  indent-style               = "space"
+  line-ending                = "auto"
+  preview                    = true
+  quote-style                = "double"
+  skip-magic-trailing-comma  = false

e5ef87720cb8d62788e44c4c940fa300694a7308 2025-08-02T10:47:36-04:00---
 LICENSE            | 21 ---------------------
 pyproject.toml     | 39 ++++++++++++++++++---------------------
 ruff.default.toml  | 18 +++++++++++++++---
 tests/test_main.py |  6 +++---
 4 files changed, 36 insertions(+), 48 deletions(-)

diff --git a/LICENSE b/LICENSE
deleted file mode 100644
index c2aaf3a..0000000
--- a/LICENSE
+++ /dev/null
@@ -1,21 +0,0 @@
-MIT License
-
-Copyright (c) 2025 Joseph Courtney
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
diff --git a/pyproject.toml b/pyproject.toml
index 12a98eb..0ab0a9b 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,38 +1,38 @@
 # =================================== project ====================================
 [project]
   name = "showcov"
-  dynamic = ["version"]
+  version = "0.0.1"
   description = "Print out uncovered code."
   readme = "README.md"
   authors = [
-    { name = "Joseph M. Courtney", email = "joseph.m.courtney@gmail.com" },
+    { name = "Joseph M Courtney", email = "Joseph.M.Courtney@gmail.com" },
   ]
   urls = { "Homepage" = "https://github.com/josephcourtney/showcov", "Bug Tracker" = "https://github.com/josephcourtney/showcov/issues" }
-  license = { text = "MIT License" }
+  license = { text = "GPL-3.0-only" }
   classifiers = [
     "Development Status :: 3 - Alpha",
-    "License :: OSI Approved :: MIT License",
+    "License :: OSI Approved :: GNU General Public License (GPL)",
     "Programming Language :: Python :: 3",
     "Operating System :: OS Independent",
   ]
-  requires-python = ">=3.12"
+  requires-python = ">=3.13"
   dependencies = [
     "colorama>=0.4.6",
     "configparser>=7.1.0",
     "defusedxml>=0.7.1",
-  ]
+    "ty>=0.0.1a16",
+]
 
   [project.scripts]
     showcov = "showcov.main:main"
 
 [dependency-groups]
   dev = [
-    "basedpyright>=1.28.1",
-    "coverage>=7.6.10",
+    "ruff>=0.11.0",
+    "coverage>=7.7.0",
     "pytest-cov>=6.0.0",
-    "pytest-randomly>=3.16.0",
     "pytest>=8.3.5",
-    "ruff>=0.9.4",
+    "pytest-randomly>=3.16.0",
     "types-colorama>=0.4.15.20240311",
     "types-defusedxml>=0.7.0.20240218",
     "types-toml>=0.10.8.20240310",
@@ -40,22 +40,20 @@
 
 # =================================== build ====================================
 [build-system]
-  requires      = ["hatchling"]
-  build-backend = "hatchling.build"
+  requires      = ["uv_build>=0.6,<0.7"]
+  build-backend = "uv_build"
 
 
-[tool.hatch.build]
-  includes = ["src/showcov/**"]
-
-[tool.hatch.version]
-  path = "src/showcov/__version__.py"
-
 # ==================================== lint ====================================
 [tool.ruff]
   extend = "./ruff.default.toml"
 
   [tool.ruff.lint]
-    ignore = []
+    ignore = [
+      # "TD002",  # Missing author in TODO; try: `# TODO(<author_name>): ...` or `# TODO @<author_name>: ...`
+      # "TD003",  # Missing issue link for this TODO
+      # "FIX002", # Line contains TODO, consider resolving the issue
+    ]
 
 # =================================== typecheck ===================================
 [tool.basedpyright]
@@ -71,7 +69,6 @@
 
 
   # =================================== test ===================================
-
 [tool.pytest.ini_options]
   addopts = [
     "--cov=showcov",
@@ -82,7 +79,7 @@
 
 # =================================== test:coverage ===================================
 [tool.coverage.run]
-  source   = ["."]
+  source   = ["src/showcov"]
   branch   = true
   parallel = true
 
diff --git a/ruff.default.toml b/ruff.default.toml
index 8be596c..3057dfd 100644
--- a/ruff.default.toml
+++ b/ruff.default.toml
@@ -129,12 +129,24 @@ respect-gitignore = true
 
   [lint.per-file-ignores]
     "tests/**/*.py" = [
-      "S101",    # Use of `assert` detected
-      "PLR2004", # Magic value used in comparison
-      "SLF001",  # Private member accessed
+      "ANN202",  # Missing return type annotation for private function
+      "ANN401",  # Dynamically typed expressions (typing.Any) are disallowed in `renderable`
+      "ARG001",  # Unused function argument
+      "ARG002",  # Unused method argument
+      "ARG005",  # Unused lambda argument
+      "D105",    # Missing docstring in magic method
+      "FBT003",  # Boolean default value in function definition
+      "N803",    # Argument name should be lowercase
+      "N806",    # Variable in function should be lowercase
+      "PLC0415", # `import` should be at the top-level of a file
       "PLC2701", # Private name import from external module
+      "PLR2004", # Magic value used in comparison
+      "PLR6301", # Method could be a function
+      "S101",    # Use of `assert` detected
       "S404",    # `subprocess` module is possibly insecure
       "S603",    # `subprocess` call: check for execution of untrusted
+      "SLF001",  # Private member accessed
+      "PLC0415", # `import` should be at the top-level of a file
     ]
 
     # disable autofix when linting
diff --git a/tests/test_main.py b/tests/test_main.py
index 3b1c0d9..f76e508 100644
--- a/tests/test_main.py
+++ b/tests/test_main.py
@@ -237,7 +237,7 @@ def test_get_xml_from_config_exception(monkeypatch, tmp_path):
     config_file.write_text("some invalid content")
 
     # Force an exception when reading the config file so that the exception branch is taken.
-    def fake_read(self, filenames, encoding=None):  # noqa: ARG001
+    def fake_read(self, filenames, encoding=None):
         msg = "simulated error"
         raise OSError(msg)
 
@@ -254,7 +254,7 @@ def test_get_xml_from_pyproject_exception(monkeypatch, tmp_path):
     pyproject.write_text("invalid content")
 
     # Force an exception during tomllib.load to simulate a failure parsing the pyproject.toml.
-    def fake_tomllib_load(f):  # noqa: ARG001
+    def fake_tomllib_load(f):
         msg = "simulated error"
         raise OSError(msg)
 
@@ -313,7 +313,7 @@ def test_print_uncovered_sections_file_open_error(monkeypatch, capsys, tmp_path)
 
     # Simulate an OSError when trying to open a source file. The function should catch the exception,
     # log the error, and still print the grouped line numbers.
-    def fake_open(*args, **kwargs):  # noqa: ARG001
+    def fake_open(*args, **kwargs):
         msg = "simulated file open error"
         raise OSError(msg)
 

c92014603c57930c26666c44b0b040cd79d5d717 2025-08-02T11:02:43-04:00---
 TODO.md | 138 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 138 insertions(+)

diff --git a/TODO.md b/TODO.md
new file mode 100644
index 0000000..ebb373c
--- /dev/null
+++ b/TODO.md
@@ -0,0 +1,138 @@
+### I. Output Format Refactor
+
+#### Add Output Format Option
+
+* [ ] Add CLI option `--format {human,json}` (default: `human`).
+* [ ] Modify `main()` and `print_uncovered_sections()` to dispatch based on format.
+* [ ] Abstract uncovered data into a structured internal model before formatting.
+
+#### Implement JSON Output
+
+* [ ] Assess the proposed JSON schema in the appendix for suitability.
+* [ ] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
+* [ ] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
+* [ ] Validate generated JSON matches schema using a static schema or runtime validator.
+
+### II. LLM-Focused Enhancements
+
+#### Machine-Friendliness
+
+* [ ] add a --no-color flag
+* [ ] Remove all ANSI color codes and text styling from `json` mode.
+* [ ] Normalize all paths to POSIX-style (`/`) and resolve relative paths.
+
+#### Determinism and Consistency
+
+* [ ] Ensure stable ordering: files sorted alphabetically, uncovered groups ordered numerically.
+* [ ] Avoid floating or system-dependent fields (timestamps, random hashes, etc.).
+
+#### Contextual Source Embedding (optional future support)
+
+* [ ] Add option `--embed-source` to include raw source lines under each uncovered range:
+
+  ```json
+  { "start": 136, "end": 136, "lines": ["    return groups"] }
+  ```
+
+### III. Internal Architecture Improvements
+
+#### Abstract Internal Data Model
+
+* [ ] Define `UncoveredSection(file: Path, ranges: list[tuple[int, int]])`.
+* [ ] Add model serialization methods: `.to_dict()` for JSON export.
+
+#### Decouple Output from Logic
+
+* [ ] Move all printing/formatting into dedicated module: `showcov/output.py`.
+* [ ] Allow output selection via a registry or strategy pattern.
+
+### IV. Protocol/Tooling Integration Readiness
+
+#### Context Protocol Support
+
+* [ ] Design output to conform to emerging context-tool protocols (e.g. OpenAI tool-calling, LangChain toolkits).
+* [ ] Ensure that output JSON is valid with `application/json` MIME type, no extra preamble or wrapper.
+
+#### CLI + API Parity
+
+* [ ] Expose main logic as a function callable via API:
+  `get_coverage_data(xml_path: Path) -> list[UncoveredSection]`
+
+#### JSON Schema + Type Hints
+
+* [ ] Provide a `schema.json` file for the JSON output format.
+* [ ] Annotate output functions with complete type hints using `TypedDict` or `pydantic.BaseModel`.
+
+### V. Testing Enhancements
+
+#### Add Format-Specific Tests
+
+* [ ] Add tests for `--format json` using `json.loads` and structural assertions.
+* [ ] Add round-trip validation: uncovered → JSON → parsed → == original.
+
+#### Ensure LLM Usability
+
+* [ ] Add snapshot tests of JSON output and sample prompts to LLMs for smoke-checking usability.
+
+## Appendix
+### Proposed JSON Schema
+```json
+```json
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://example.com/showcov.schema.json",
+  "title": "Showcov Coverage Report",
+  "type": "object",
+  "properties": {
+    "version": {
+      "description": "Version of the showcov tool or schema.",
+      "type": "string",
+      "pattern": "^\\d+\\.\\d+\\.\\d+$"
+    },
+    "files": {
+      "description": "List of source files with uncovered code sections.",
+      "type": "array",
+      "items": {
+        "type": "object",
+        "properties": {
+          "file": {
+            "description": "Path to the source file.",
+            "type": "string"
+          },
+          "uncovered": {
+            "description": "List of uncovered line ranges.",
+            "type": "array",
+            "items": {
+              "type": "object",
+              "properties": {
+                "start": {
+                  "type": "integer",
+                  "minimum": 1
+                },
+                "end": {
+                  "type": "integer",
+                  "minimum": 1
+                },
+                "lines": {
+                  "description": "Optional source code lines in this range.",
+                  "type": "array",
+                  "items": {
+                    "type": "string"
+                  },
+                  "minItems": 1
+                }
+              },
+              "required": ["start", "end"],
+              "additionalProperties": false
+            }
+          }
+        },
+        "required": ["file", "uncovered"],
+        "additionalProperties": false
+      }
+    }
+  },
+  "required": ["version", "files"],
+  "additionalProperties": false
+}
+```

8d441c6254657ae6bca3ccf4105ee086c38f10bf 2025-08-02T11:19:17-04:00---
 AGENTS.md      | 70 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 pyproject.toml |  8 +++----
 2 files changed, 74 insertions(+), 4 deletions(-)

diff --git a/AGENTS.md b/AGENTS.md
new file mode 100644
index 0000000..097edb3
--- /dev/null
+++ b/AGENTS.md
@@ -0,0 +1,70 @@
+## Purpose
+
+This file defines how coding agents (LLMs, autonomous dev tools, etc.) should operate when contributing to this project.
+
+## Role
+
+You are an assistant contributing to `showcov`, a CLI tool that identifies uncovered lines in Python source files from a coverage XML report.
+
+Your responsibilities include:
+- Editing Python source files under `src/showcov/`
+- Editing or creating test files under `tests/`
+- Maintaining output determinism, testability, and format extensibility
+- Respecting existing CLI design and internal architecture
+
+## Directories
+
+- Source code: `src/showcov/`
+- Tests: `tests/`
+- Do not create or modify files outside these directories unless explicitly instructed.
+
+## Tooling Requirements
+
+You must use the following tools for validation and conformance before proposing code:
+
+### Linting
+- Run: `ruff check src/ tests/`
+- Use rules defined in `pyproject.toml` and any referenced `ruff.default.toml`
+
+### Formatting
+- Run: `ruff format src/ tests/`
+
+### Static Typing
+- Run: `ty check src/ tests/`
+- Use Python 3.13–compatible type syntax.
+- Respect constraints in `pyproject.toml`
+
+### Testing
+- Run: `pytest`
+- `pytest` should follow the settings in `pyproject.toml`
+- Add test coverage for new features or regression paths.
+- Use deterministic test data and avoid system-dependent values (e.g., timestamps, absolute paths).
+
+## Behavior Constraints
+
+- **Path normalization**: always use POSIX-style (`/`) paths in output and JSON.
+- **Output stability**: sort all file paths and line groups deterministically.
+- **No ANSI styling** in non-human formats (e.g., JSON).
+- **No I/O outside of `src/` or `tests/`** unless instructed.
+
+## Commit Standards
+
+- Each commit should pass:  
+  - `ruff check && ruff format`  
+  - `ty check`  
+  - `pytest`
+
+- Prefer conventional commit messages:
+  - `feat: add --format json`
+  - `fix: handle missing <class> tag in coverage XML`
+  - `test: add tests for merge_blank_gap_groups`
+
+## Prohibited
+
+- Do not introduce new dependencies without justification in a comment.
+- Do not remove test coverage.
+- Do not introduce non-deterministic behavior.
+
+## Compliance
+
+All contributions must adhere to this protocol unless overridden by a specific user instruction or documented exception.
diff --git a/pyproject.toml b/pyproject.toml
index 0ab0a9b..222673e 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -20,8 +20,7 @@
     "colorama>=0.4.6",
     "configparser>=7.1.0",
     "defusedxml>=0.7.1",
-    "ty>=0.0.1a16",
-]
+  ]
 
   [project.scripts]
     showcov = "showcov.main:main"
@@ -29,9 +28,10 @@
 [dependency-groups]
   dev = [
     "ruff>=0.11.0",
+    "ty>=0.0.1a16",
+    "pytest>=8.3.5",
     "coverage>=7.7.0",
     "pytest-cov>=6.0.0",
-    "pytest>=8.3.5",
     "pytest-randomly>=3.16.0",
     "types-colorama>=0.4.15.20240311",
     "types-defusedxml>=0.7.0.20240218",
@@ -68,7 +68,7 @@
   ]
 
 
-  # =================================== test ===================================
+# =================================== test ===================================
 [tool.pytest.ini_options]
   addopts = [
     "--cov=showcov",

656e0f15b97efa1e06ac8818c3cd18d7c5c5f9bf 2025-08-02T11:29:54-04:00---
 src/showcov/main.py | 35 ++++++++++++++++------
 tests/test_main.py  | 86 ++++++++++++++++++++++++++++++++++++++++++++++++-----
 2 files changed, 105 insertions(+), 16 deletions(-)

diff --git a/src/showcov/main.py b/src/showcov/main.py
index a92442b..91e43d1 100644
--- a/src/showcov/main.py
+++ b/src/showcov/main.py
@@ -7,12 +7,13 @@ a configuration file (pyproject.toml, .coveragerc, or setup.cfg).
 
 import argparse
 import logging
+import operator
 import sys
 import tomllib
 from configparser import ConfigParser
 from configparser import Error as ConfigError
 from pathlib import Path
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Optional, cast
 
 from colorama import Fore, Style
 from colorama import init as colorama_init
@@ -41,6 +42,12 @@ logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
 logger = logging.getLogger(__name__)
 
 
+def disable_colors() -> None:
+    """Disable ANSI color codes."""
+    global RESET, BOLD, YELLOW, CYAN, MAGENTA, GREEN, RED  # noqa: PLW0603
+    RESET = BOLD = YELLOW = CYAN = MAGENTA = GREEN = RED = ""
+
+
 class CoverageXMLNotFoundError(Exception):
     """Coverage XML file not found."""
 
@@ -97,12 +104,18 @@ def parse_args() -> argparse.Namespace:
     """Parse command-line arguments."""
     parser = argparse.ArgumentParser(description="Show uncovered lines from a coverage XML report.")
     parser.add_argument("xml_file", nargs="?", help="Path to coverage XML file")
+    parser.add_argument(
+        "--no-color",
+        action="store_true",
+        help="Disable ANSI color codes in output",
+    )
     return parser.parse_args()
 
 
-def determine_xml_file() -> Path:
+def determine_xml_file(args: argparse.Namespace | None = None) -> Path:
     """Determine the coverage XML file path from arguments or config."""
-    args = parse_args()
+    if args is None:
+        args = parse_args()
     if args.xml_file:
         return Path(args.xml_file)
 
@@ -151,10 +164,11 @@ def merge_blank_gap_groups(groups: list[list[int]], file_lines: list[str]) -> li
 
 def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
     """Print uncovered sections from files."""
-    for filename, lines in uncovered.items():
-        lines_sorted = sorted(lines)
+    for filename in sorted(uncovered.keys(), key=lambda p: p.as_posix()):
+        lines_sorted = sorted(uncovered[filename])
         groups = group_consecutive_numbers(lines_sorted)
-        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename}:{RESET}")
+        groups = sorted(groups, key=operator.itemgetter(0))
+        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename.as_posix()}:{RESET}")
 
         try:
             with filename.open(encoding="utf-8") as f:
@@ -203,7 +217,7 @@ def _gather_uncovered_lines(root: "Element") -> dict[Path, list[int]]:
         resolved_path = next(
             (src / filename for src in source_roots if (src / filename).exists()),
             filename,  # fallback to relative path if none match
-        )
+        ).resolve()
 
         for line in cls.findall("lines/line"):
             try:
@@ -229,8 +243,11 @@ def parse_large_xml(file_path: Path) -> Optional["Element"]:
 
 def main() -> None:
     """Entry point for the script."""
+    args = parse_args()
+    if args.no_color:
+        disable_colors()
     try:
-        xml_file: Path = determine_xml_file()
+        xml_file: Path = determine_xml_file(args)
     except CoverageXMLNotFoundError:
         sys.exit(1)
 
@@ -246,7 +263,7 @@ def main() -> None:
         logger.exception("Error opening XML file %s", xml_file)
         sys.exit(1)
 
-    uncovered = _gather_uncovered_lines(root)
+    uncovered = _gather_uncovered_lines(cast("Element", root))
 
     if not uncovered:
         print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
diff --git a/tests/test_main.py b/tests/test_main.py
index f76e508..7d74dc8 100644
--- a/tests/test_main.py
+++ b/tests/test_main.py
@@ -16,6 +16,7 @@ from showcov.main import (
     _get_xml_from_config,
     _get_xml_from_pyproject,
     determine_xml_file,
+    disable_colors,
     get_config_xml_file,
     group_consecutive_numbers,
     main,
@@ -91,6 +92,7 @@ def test_parse_args_no_file(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
     assert args.xml_file is None
+    assert args.no_color is False
 
 
 def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
@@ -98,6 +100,14 @@ def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
     assert args.xml_file == "coverage.xml"
+    assert args.no_color is False
+
+
+def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "--no-color"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    args = parse_args()
+    assert args.no_color is True
 
 
 # --- Tests for `print_uncovered_sections` ---
@@ -116,6 +126,29 @@ def test_print_uncovered_sections(tmp_path: Path, capsys: CaptureFixture) -> Non
     assert "5" in captured
 
 
+def test_print_uncovered_sections_no_color(tmp_path: Path, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("print('hi')\n")
+    uncovered = {source_file: [1]}
+    disable_colors()
+    print_uncovered_sections(uncovered)
+    captured = capsys.readouterr().out
+    assert "\x1b" not in captured
+
+
+def test_print_uncovered_sections_sorted_files(tmp_path: Path, capsys: CaptureFixture) -> None:
+    file_b = tmp_path / "b.py"
+    file_a = tmp_path / "a.py"
+    file_a.write_text("a=1\n")
+    file_b.write_text("b=1\n")
+    uncovered = {file_b: [1], file_a: [1]}
+    print_uncovered_sections(uncovered)
+    captured = capsys.readouterr().out
+    first = captured.find(file_a.as_posix())
+    second = captured.find(file_b.as_posix())
+    assert first < second
+
+
 # --- Tests for `_gather_uncovered_lines` ---
 
 
@@ -138,8 +171,9 @@ def test_gather_uncovered_lines_invalid_hits() -> None:
     """)
     root = ElementTree.fromstring(xml_content)
     uncovered = _gather_uncovered_lines(root)
-    assert Path("dummy.py") in uncovered
-    assert uncovered[Path("dummy.py")] == [2]
+    key = next(iter(uncovered))
+    assert key.name == "dummy.py"
+    assert uncovered[key] == [2]
 
 
 # --- Tests for `parse_large_xml` ---
@@ -165,9 +199,41 @@ def test_parse_large_xml(tmp_path: Path) -> None:
     xml_file = tmp_path / "coverage.xml"
     xml_file.write_text(xml_content)
     root = parse_large_xml(xml_file)
+    assert root is not None
     uncovered = _gather_uncovered_lines(root)
-    assert Path("dummy.py") in uncovered
-    assert uncovered[Path("dummy.py")] == [3, 5]
+    key = next(iter(uncovered))
+    assert key.name == "dummy.py"
+    assert uncovered[key] == [3, 5]
+
+
+def test_gather_uncovered_lines_resolves_paths(tmp_path: Path) -> None:
+    pkg = tmp_path / "pkg"
+    pkg.mkdir()
+    source_file = pkg / "dummy.py"
+    source_file.write_text("print('hi')\n")
+    xml_content = f"""
+    <coverage>
+      <sources>
+        <source>{tmp_path}</source>
+      </sources>
+      <packages>
+        <package>
+          <classes>
+            <class filename="pkg/dummy.py">
+              <lines>
+                <line number="1" hits="0"/>
+              </lines>
+            </class>
+          </classes>
+        </package>
+      </packages>
+    </coverage>
+    """
+    root = ElementTree.fromstring(xml_content)
+    uncovered = _gather_uncovered_lines(root)
+    key = next(iter(uncovered))
+    assert key.is_absolute()
+    assert key.as_posix().endswith("pkg/dummy.py")
 
 
 # --- Tests for `main()` ---
@@ -341,19 +407,22 @@ def test_parse_large_xml_no_coverage(tmp_path):
 
 def test_main_coverage_xml_not_found(monkeypatch):
     # Force determine_xml_file to throw CoverageXMLNotFoundError and verify that main() calls sys.exit(1).
+    monkeypatch.setattr(sys, "argv", ["prog"])
     monkeypatch.setattr(
         "showcov.main.determine_xml_file",
-        lambda: (_ for _ in ()).throw(CoverageXMLNotFoundError("No coverage XML file specified")),
+        lambda _args: (_ for _ in ()).throw(CoverageXMLNotFoundError("No coverage XML file specified")),
     )
     with pytest.raises(SystemExit) as exc_info:
         main()
+    assert isinstance(exc_info.value, SystemExit)
     assert exc_info.value.code == 1
 
 
 def test_main_parse_error(monkeypatch):
     # Force parse_large_xml to raise an ElementTree.ParseError and verify that main() calls sys.exit(1).
     fake_path = Path("dummy.xml")
-    monkeypatch.setattr("showcov.main.determine_xml_file", lambda: fake_path)
+    monkeypatch.setattr(sys, "argv", ["prog"])
+    monkeypatch.setattr("showcov.main.determine_xml_file", lambda _args: fake_path)
 
     def fake_parse_large_xml(_):
         msg = "simulated parse error"
@@ -362,13 +431,15 @@ def test_main_parse_error(monkeypatch):
     monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
     with pytest.raises(SystemExit) as exc_info:
         main()
+    assert isinstance(exc_info.value, SystemExit)
     assert exc_info.value.code == 1
 
 
 def test_main_os_error(monkeypatch):
     # Force parse_large_xml to raise an OSError and verify that main() calls sys.exit(1).
     fake_path = Path("dummy.xml")
-    monkeypatch.setattr("showcov.main.determine_xml_file", lambda: fake_path)
+    monkeypatch.setattr(sys, "argv", ["prog"])
+    monkeypatch.setattr("showcov.main.determine_xml_file", lambda _args: fake_path)
 
     def fake_parse_large_xml(_):
         msg = "simulated OS error"
@@ -377,4 +448,5 @@ def test_main_os_error(monkeypatch):
     monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
     with pytest.raises(SystemExit) as exc_info:
         main()
+    assert isinstance(exc_info.value, SystemExit)
     assert exc_info.value.code == 1

04d206524089d364fb1cb0a83420a50ca72938a5 2025-08-02T11:31:29-04:00
1294a2ad16270a552aff1ced73b31864d87937d6 2025-08-02T11:55:42-04:00---
 .grobl.config.json                   |   1 +
 AGENTS.md                            |   2 +-
 TODO.md                              |   6 +-
 pyproject.toml                       |   2 +-
 src/showcov/__init__.py              |   5 ++
 src/showcov/__main__.py              |  11 +++
 src/showcov/__version__.py           |   1 -
 src/showcov/cli.py                   | 131 +++++++++++++++++++++++++++++++++++
 src/showcov/{main.py => core.py}     | 124 ++++-----------------------------
 tests/test_cli.py                    |   0
 tests/{test_main.py => test_core.py} |  55 ++++++++-------
 11 files changed, 196 insertions(+), 142 deletions(-)

diff --git a/.grobl.config.json b/.grobl.config.json
index 14b44fc..3e7e1b3 100644
--- a/.grobl.config.json
+++ b/.grobl.config.json
@@ -1,5 +1,6 @@
 {
   "exclude_tree": [
+    "__pycache__/",
     "*.egg-info",
     "*.ipynb",
     ".git/",
diff --git a/AGENTS.md b/AGENTS.md
index 097edb3..b260e0e 100644
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -45,7 +45,7 @@ You must use the following tools for validation and conformance before proposing
 - **Path normalization**: always use POSIX-style (`/`) paths in output and JSON.
 - **Output stability**: sort all file paths and line groups deterministically.
 - **No ANSI styling** in non-human formats (e.g., JSON).
-- **No I/O outside of `src/` or `tests/`** unless instructed.
+- **No I/O outside of `src/`, `tests/`, or `TODO.md`** unless instructed.
 
 ## Commit Standards
 
diff --git a/TODO.md b/TODO.md
index ebb373c..67e9e60 100644
--- a/TODO.md
+++ b/TODO.md
@@ -17,13 +17,13 @@
 
 #### Machine-Friendliness
 
-* [ ] add a --no-color flag
+* [x] add a --no-color flag
 * [ ] Remove all ANSI color codes and text styling from `json` mode.
 * [ ] Normalize all paths to POSIX-style (`/`) and resolve relative paths.
 
 #### Determinism and Consistency
 
-* [ ] Ensure stable ordering: files sorted alphabetically, uncovered groups ordered numerically.
+* [x] Ensure stable ordering: files sorted alphabetically, uncovered groups ordered numerically.
 * [ ] Avoid floating or system-dependent fields (timestamps, random hashes, etc.).
 
 #### Contextual Source Embedding (optional future support)
@@ -55,7 +55,7 @@
 
 #### CLI + API Parity
 
-* [ ] Expose main logic as a function callable via API:
+* [x] Expose main logic as a function callable via API:
   `get_coverage_data(xml_path: Path) -> list[UncoveredSection]`
 
 #### JSON Schema + Type Hints
diff --git a/pyproject.toml b/pyproject.toml
index 222673e..83e9bd3 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -23,7 +23,7 @@
   ]
 
   [project.scripts]
-    showcov = "showcov.main:main"
+    showcov = "showcov.cli:main"
 
 [dependency-groups]
   dev = [
diff --git a/src/showcov/__init__.py b/src/showcov/__init__.py
index e69de29..1e50d83 100644
--- a/src/showcov/__init__.py
+++ b/src/showcov/__init__.py
@@ -0,0 +1,5 @@
+from importlib.metadata import version
+
+__all__ = ["__version__"]
+
+__version__ = version("showcov")
diff --git a/src/showcov/__main__.py b/src/showcov/__main__.py
new file mode 100644
index 0000000..df67358
--- /dev/null
+++ b/src/showcov/__main__.py
@@ -0,0 +1,11 @@
+"""Entry-point module, invoked with `python -m bingbong`.
+
+Why does this file exist, and why __main__? For more info, read:
+- https://www.python.org/dev/peps/pep-0338/
+- https://docs.python.org/3/using/cmdline.html#cmdoption-m
+"""
+
+from .cli import main
+
+if __name__ == "__main__":
+    main()
diff --git a/src/showcov/__version__.py b/src/showcov/__version__.py
deleted file mode 100644
index 00ec2dc..0000000
--- a/src/showcov/__version__.py
+++ /dev/null
@@ -1 +0,0 @@
-__version__ = "0.0.9"
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
new file mode 100644
index 0000000..b143be6
--- /dev/null
+++ b/src/showcov/cli.py
@@ -0,0 +1,131 @@
+import argparse
+import logging
+import operator
+import sys
+from pathlib import Path
+from typing import TYPE_CHECKING, cast
+
+from colorama import Fore, Style
+from colorama import init as colorama_init
+from defusedxml import ElementTree
+
+from .core import (
+    CoverageXMLNotFoundError,
+    determine_xml_file,
+    gather_uncovered_lines,
+    group_consecutive_numbers,
+    merge_blank_gap_groups,
+    parse_large_xml,
+)
+
+# Initialize colorama
+colorama_init(autoreset=True)
+
+if TYPE_CHECKING:
+    from xml.etree.ElementTree import Element  # noqa: S405
+
+# ANSI color codes (cross-platform)
+RESET = Style.RESET_ALL
+BOLD = Style.BRIGHT
+YELLOW = Fore.YELLOW
+CYAN = Fore.CYAN
+MAGENTA = Fore.MAGENTA
+GREEN = Fore.GREEN
+RED = Fore.RED
+
+# Constants
+CONSECUTIVE_STEP = 1
+
+# Configure logging
+logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
+logger = logging.getLogger(__name__)
+
+
+def disable_colors() -> None:
+    """Disable ANSI color codes."""
+    global RESET, BOLD, YELLOW, CYAN, MAGENTA, GREEN, RED  # noqa: PLW0603
+    RESET = BOLD = YELLOW = CYAN = MAGENTA = GREEN = RED = ""
+
+
+def parse_args() -> argparse.Namespace:
+    """Parse command-line arguments."""
+    parser = argparse.ArgumentParser(description="Show uncovered lines from a coverage XML report.")
+    parser.add_argument("xml_file", nargs="?", help="Path to coverage XML file")
+    parser.add_argument(
+        "--no-color",
+        action="store_true",
+        help="Disable ANSI color codes in output",
+    )
+    return parser.parse_args()
+
+
+def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
+    """Print uncovered sections from files."""
+    for filename in sorted(uncovered.keys(), key=lambda p: p.as_posix()):
+        lines_sorted = sorted(uncovered[filename])
+        groups = group_consecutive_numbers(lines_sorted)
+        groups = sorted(groups, key=operator.itemgetter(0))
+        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename.as_posix()}:{RESET}")
+
+        try:
+            with filename.open(encoding="utf-8") as f:
+                file_lines = f.readlines()
+            groups = merge_blank_gap_groups(groups, file_lines)
+        except OSError:
+            logger.exception("Could not open %s", filename)
+            for grp in groups:
+                print(
+                    f"  {CYAN}Lines {grp[0]}-{grp[-1]}{RESET}"
+                    if len(grp) > 1
+                    else f"  {CYAN}Line {grp[0]}{RESET}"
+                )
+            continue
+
+        for grp in groups:
+            header = (
+                f"  {BOLD}{CYAN}Lines {grp[0]}-{grp[-1]}:{RESET}"
+                if len(grp) > 1
+                else f"  {BOLD}{CYAN}Line {grp[0]}:{RESET}"
+            )
+            print(header)
+            for ln in grp:
+                content = (
+                    file_lines[ln - 1].rstrip("\n") if 1 <= ln <= len(file_lines) else "<line not found>"
+                )
+                print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
+            print()
+
+
+def main() -> None:
+    """Entry point for the script."""
+    args = parse_args()
+    if args.no_color:
+        disable_colors()
+    try:
+        xml_file: Path = determine_xml_file(args.xml_file)
+    except CoverageXMLNotFoundError:
+        sys.exit(1)
+
+    try:
+        root = parse_large_xml(xml_file)
+        if root is None:
+            logger.error("Failed to parse coverage XML file: %s", xml_file)
+            sys.exit(1)
+    except ElementTree.ParseError:
+        logger.exception("Error parsing XML file %s", xml_file)
+        sys.exit(1)
+    except OSError:
+        logger.exception("Error opening XML file %s", xml_file)
+        sys.exit(1)
+
+    uncovered = gather_uncovered_lines(cast("Element", root))
+
+    if not uncovered:
+        print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
+        return
+
+    print_uncovered_sections(uncovered)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/src/showcov/main.py b/src/showcov/core.py
similarity index 58%
rename from src/showcov/main.py
rename to src/showcov/core.py
index 91e43d1..ec2482a 100644
--- a/src/showcov/main.py
+++ b/src/showcov/core.py
@@ -5,34 +5,19 @@ If no XML filename is given as a command-line argument, the script will try to r
 a configuration file (pyproject.toml, .coveragerc, or setup.cfg).
 """
 
-import argparse
 import logging
-import operator
-import sys
 import tomllib
+from argparse import Namespace
 from configparser import ConfigParser
 from configparser import Error as ConfigError
 from pathlib import Path
-from typing import TYPE_CHECKING, Optional, cast
+from typing import TYPE_CHECKING, Optional
 
-from colorama import Fore, Style
-from colorama import init as colorama_init
 from defusedxml import ElementTree
 
-# Initialize colorama
-colorama_init(autoreset=True)
-
 if TYPE_CHECKING:
     from xml.etree.ElementTree import Element  # noqa: S405
 
-# ANSI color codes (cross-platform)
-RESET = Style.RESET_ALL
-BOLD = Style.BRIGHT
-YELLOW = Fore.YELLOW
-CYAN = Fore.CYAN
-MAGENTA = Fore.MAGENTA
-GREEN = Fore.GREEN
-RED = Fore.RED
 
 # Constants
 CONSECUTIVE_STEP = 1
@@ -42,12 +27,6 @@ logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
 logger = logging.getLogger(__name__)
 
 
-def disable_colors() -> None:
-    """Disable ANSI color codes."""
-    global RESET, BOLD, YELLOW, CYAN, MAGENTA, GREEN, RED  # noqa: PLW0603
-    RESET = BOLD = YELLOW = CYAN = MAGENTA = GREEN = RED = ""
-
-
 class CoverageXMLNotFoundError(Exception):
     """Coverage XML file not found."""
 
@@ -100,24 +79,17 @@ def get_config_xml_file() -> str | None:
     return None
 
 
-def parse_args() -> argparse.Namespace:
-    """Parse command-line arguments."""
-    parser = argparse.ArgumentParser(description="Show uncovered lines from a coverage XML report.")
-    parser.add_argument("xml_file", nargs="?", help="Path to coverage XML file")
-    parser.add_argument(
-        "--no-color",
-        action="store_true",
-        help="Disable ANSI color codes in output",
-    )
-    return parser.parse_args()
+def determine_xml_file(xml_file: Namespace | None = None) -> Path:
+    """Determine the coverage XML file path from arguments or config.
 
+    Accepts either a Namespace with attribute `xml_file` or a raw path string/None.
+    """
+    # Normalize input: allow passing argparse.Namespace or raw string/None.
+    if hasattr(xml_file, "xml_file"):
+        xml_file = xml_file.xml_file
 
-def determine_xml_file(args: argparse.Namespace | None = None) -> Path:
-    """Determine the coverage XML file path from arguments or config."""
-    if args is None:
-        args = parse_args()
-    if args.xml_file:
-        return Path(args.xml_file)
+    if xml_file:
+        return Path(xml_file)
 
     config_xml = get_config_xml_file()
     if config_xml:
@@ -162,44 +134,7 @@ def merge_blank_gap_groups(groups: list[list[int]], file_lines: list[str]) -> li
     return merged
 
 
-def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
-    """Print uncovered sections from files."""
-    for filename in sorted(uncovered.keys(), key=lambda p: p.as_posix()):
-        lines_sorted = sorted(uncovered[filename])
-        groups = group_consecutive_numbers(lines_sorted)
-        groups = sorted(groups, key=operator.itemgetter(0))
-        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename.as_posix()}:{RESET}")
-
-        try:
-            with filename.open(encoding="utf-8") as f:
-                file_lines = f.readlines()
-            groups = merge_blank_gap_groups(groups, file_lines)
-        except OSError:
-            logger.exception("Could not open %s", filename)
-            for grp in groups:
-                print(
-                    f"  {CYAN}Lines {grp[0]}-{grp[-1]}{RESET}"
-                    if len(grp) > 1
-                    else f"  {CYAN}Line {grp[0]}{RESET}"
-                )
-            continue
-
-        for grp in groups:
-            header = (
-                f"  {BOLD}{CYAN}Lines {grp[0]}-{grp[-1]}:{RESET}"
-                if len(grp) > 1
-                else f"  {BOLD}{CYAN}Line {grp[0]}:{RESET}"
-            )
-            print(header)
-            for ln in grp:
-                content = (
-                    file_lines[ln - 1].rstrip("\n") if 1 <= ln <= len(file_lines) else "<line not found>"
-                )
-                print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
-            print()
-
-
-def _gather_uncovered_lines(root: "Element") -> dict[Path, list[int]]:
+def gather_uncovered_lines(root: "Element") -> dict[Path, list[int]]:
     """Gather uncovered lines per file from the parsed XML tree."""
     uncovered: dict[Path, list[int]] = {}
 
@@ -239,38 +174,3 @@ def parse_large_xml(file_path: Path) -> Optional["Element"]:
         if event == "end" and elem.tag == "coverage":
             return elem  # Return root element early to save memory
     return None
-
-
-def main() -> None:
-    """Entry point for the script."""
-    args = parse_args()
-    if args.no_color:
-        disable_colors()
-    try:
-        xml_file: Path = determine_xml_file(args)
-    except CoverageXMLNotFoundError:
-        sys.exit(1)
-
-    try:
-        root = parse_large_xml(xml_file)
-        if root is None:
-            logger.error("Failed to parse coverage XML file: %s", xml_file)
-            sys.exit(1)
-    except ElementTree.ParseError:
-        logger.exception("Error parsing XML file %s", xml_file)
-        sys.exit(1)
-    except OSError:
-        logger.exception("Error opening XML file %s", xml_file)
-        sys.exit(1)
-
-    uncovered = _gather_uncovered_lines(cast("Element", root))
-
-    if not uncovered:
-        print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
-        return
-
-    print_uncovered_sections(uncovered)
-
-
-if __name__ == "__main__":
-    main()
diff --git a/tests/test_cli.py b/tests/test_cli.py
new file mode 100644
index 0000000..e69de29
diff --git a/tests/test_main.py b/tests/test_core.py
similarity index 92%
rename from tests/test_main.py
rename to tests/test_core.py
index 7d74dc8..36ff868 100644
--- a/tests/test_main.py
+++ b/tests/test_core.py
@@ -1,3 +1,4 @@
+import argparse
 import logging
 import sys
 import textwrap
@@ -9,21 +10,24 @@ from _pytest.capture import CaptureFixture
 from _pytest.monkeypatch import MonkeyPatch
 from defusedxml import ElementTree
 
+from showcov.cli import (
+    disable_colors,
+    main,
+    parse_args,
+    print_uncovered_sections,
+)
+
 # Import functions and exceptions from your module.
-from showcov.main import (
+from showcov.core import (
     CoverageXMLNotFoundError,
-    _gather_uncovered_lines,
     _get_xml_from_config,
     _get_xml_from_pyproject,
     determine_xml_file,
-    disable_colors,
+    gather_uncovered_lines,
     get_config_xml_file,
     group_consecutive_numbers,
-    main,
     merge_blank_gap_groups,
-    parse_args,
     parse_large_xml,
-    print_uncovered_sections,
 )
 
 # Set logging level to capture output for tests
@@ -67,21 +71,21 @@ def test_get_config_xml_file_pyproject(monkeypatch: MonkeyPatch, tmp_path: Path)
 def test_determine_xml_file_argument(monkeypatch: MonkeyPatch) -> None:
     test_args = ["prog", "coverage.xml"]
     monkeypatch.setattr(sys, "argv", test_args)
-    assert determine_xml_file() == Path("coverage.xml")
+    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml")
 
 
 def test_determine_xml_file_from_config(monkeypatch: MonkeyPatch) -> None:
     test_args = ["prog"]
     monkeypatch.setattr(sys, "argv", test_args)
-    monkeypatch.setattr("showcov.main.get_config_xml_file", lambda: "coverage.xml")
-    assert determine_xml_file() == Path("coverage.xml")
+    monkeypatch.setattr("showcov.core.get_config_xml_file", lambda: "coverage.xml")
+    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml")
 
 
 def test_determine_xml_file_no_args(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", ["prog"])
-    monkeypatch.setattr("showcov.main.get_config_xml_file", lambda: None)
+    monkeypatch.setattr("showcov.core.get_config_xml_file", lambda: None)
     with pytest.raises(CoverageXMLNotFoundError, match="No coverage XML file specified"):
-        determine_xml_file()
+        determine_xml_file(xml_file=None)
 
 
 # --- Tests for `parse_args` ---
@@ -149,7 +153,7 @@ def test_print_uncovered_sections_sorted_files(tmp_path: Path, capsys: CaptureFi
     assert first < second
 
 
-# --- Tests for `_gather_uncovered_lines` ---
+# --- Tests for `gather_uncovered_lines` ---
 
 
 def test_gather_uncovered_lines_invalid_hits() -> None:
@@ -170,7 +174,7 @@ def test_gather_uncovered_lines_invalid_hits() -> None:
     </coverage>
     """)
     root = ElementTree.fromstring(xml_content)
-    uncovered = _gather_uncovered_lines(root)
+    uncovered = gather_uncovered_lines(root)
     key = next(iter(uncovered))
     assert key.name == "dummy.py"
     assert uncovered[key] == [2]
@@ -200,7 +204,7 @@ def test_parse_large_xml(tmp_path: Path) -> None:
     xml_file.write_text(xml_content)
     root = parse_large_xml(xml_file)
     assert root is not None
-    uncovered = _gather_uncovered_lines(root)
+    uncovered = gather_uncovered_lines(root)
     key = next(iter(uncovered))
     assert key.name == "dummy.py"
     assert uncovered[key] == [3, 5]
@@ -230,7 +234,7 @@ def test_gather_uncovered_lines_resolves_paths(tmp_path: Path) -> None:
     </coverage>
     """
     root = ElementTree.fromstring(xml_content)
-    uncovered = _gather_uncovered_lines(root)
+    uncovered = gather_uncovered_lines(root)
     key = next(iter(uncovered))
     assert key.is_absolute()
     assert key.as_posix().endswith("pkg/dummy.py")
@@ -324,7 +328,7 @@ def test_get_xml_from_pyproject_exception(monkeypatch, tmp_path):
         msg = "simulated error"
         raise OSError(msg)
 
-    monkeypatch.setattr("showcov.main.tomllib.load", fake_tomllib_load)
+    monkeypatch.setattr("showcov.core.tomllib.load", fake_tomllib_load)
     result = _get_xml_from_pyproject(pyproject)
     assert result is None
 
@@ -408,10 +412,13 @@ def test_parse_large_xml_no_coverage(tmp_path):
 def test_main_coverage_xml_not_found(monkeypatch):
     # Force determine_xml_file to throw CoverageXMLNotFoundError and verify that main() calls sys.exit(1).
     monkeypatch.setattr(sys, "argv", ["prog"])
-    monkeypatch.setattr(
-        "showcov.main.determine_xml_file",
-        lambda _args: (_ for _ in ()).throw(CoverageXMLNotFoundError("No coverage XML file specified")),
-    )
+
+    def fail(*_):
+        msg = "No coverage XML file specified"
+        raise CoverageXMLNotFoundError(msg)
+
+    monkeypatch.setattr("showcov.core.determine_xml_file", fail)
+
     with pytest.raises(SystemExit) as exc_info:
         main()
     assert isinstance(exc_info.value, SystemExit)
@@ -422,13 +429,13 @@ def test_main_parse_error(monkeypatch):
     # Force parse_large_xml to raise an ElementTree.ParseError and verify that main() calls sys.exit(1).
     fake_path = Path("dummy.xml")
     monkeypatch.setattr(sys, "argv", ["prog"])
-    monkeypatch.setattr("showcov.main.determine_xml_file", lambda _args: fake_path)
+    monkeypatch.setattr("showcov.core.determine_xml_file", lambda _args: fake_path)
 
     def fake_parse_large_xml(_):
         msg = "simulated parse error"
         raise ElementTree.ParseError(msg)
 
-    monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
+    monkeypatch.setattr("showcov.core.parse_large_xml", fake_parse_large_xml)
     with pytest.raises(SystemExit) as exc_info:
         main()
     assert isinstance(exc_info.value, SystemExit)
@@ -439,13 +446,13 @@ def test_main_os_error(monkeypatch):
     # Force parse_large_xml to raise an OSError and verify that main() calls sys.exit(1).
     fake_path = Path("dummy.xml")
     monkeypatch.setattr(sys, "argv", ["prog"])
-    monkeypatch.setattr("showcov.main.determine_xml_file", lambda _args: fake_path)
+    monkeypatch.setattr("showcov.core.determine_xml_file", lambda _args: fake_path)
 
     def fake_parse_large_xml(_):
         msg = "simulated OS error"
         raise OSError(msg)
 
-    monkeypatch.setattr("showcov.main.parse_large_xml", fake_parse_large_xml)
+    monkeypatch.setattr("showcov.core.parse_large_xml", fake_parse_large_xml)
     with pytest.raises(SystemExit) as exc_info:
         main()
     assert isinstance(exc_info.value, SystemExit)

58fee16ea6a86e04ee7b3c711e7cc4abd798f6f6 2025-08-02T12:17:19-04:00---
 TODO.md             | 12 ++++----
 src/showcov/cli.py  | 35 ++++++++++++++++++++++--
 src/showcov/core.py |  4 +--
 tests/test_cli.py   | 79 +++++++++++++++++++++++++++++++++++++++++++++++++++++
 tests/test_core.py  | 14 ++++++++--
 5 files changed, 131 insertions(+), 13 deletions(-)

diff --git a/TODO.md b/TODO.md
index 67e9e60..d337a7a 100644
--- a/TODO.md
+++ b/TODO.md
@@ -2,14 +2,14 @@
 
 #### Add Output Format Option
 
-* [ ] Add CLI option `--format {human,json}` (default: `human`).
-* [ ] Modify `main()` and `print_uncovered_sections()` to dispatch based on format.
+* [x] Add CLI option `--format {human,json}` (default: `human`).
+* [x] Modify `main()` and `print_uncovered_sections()` to dispatch based on format.
 * [ ] Abstract uncovered data into a structured internal model before formatting.
 
 #### Implement JSON Output
 
 * [ ] Assess the proposed JSON schema in the appendix for suitability.
-* [ ] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
+* [x] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
 * [ ] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
 * [ ] Validate generated JSON matches schema using a static schema or runtime validator.
 
@@ -18,8 +18,8 @@
 #### Machine-Friendliness
 
 * [x] add a --no-color flag
-* [ ] Remove all ANSI color codes and text styling from `json` mode.
-* [ ] Normalize all paths to POSIX-style (`/`) and resolve relative paths.
+* [x] Remove all ANSI color codes and text styling from `json` mode.
+* [x] Normalize all paths to POSIX-style (`/`) and resolve relative paths.
 
 #### Determinism and Consistency
 
@@ -67,7 +67,7 @@
 
 #### Add Format-Specific Tests
 
-* [ ] Add tests for `--format json` using `json.loads` and structural assertions.
+* [x] Add tests for `--format json` using `json.loads` and structural assertions.
 * [ ] Add round-trip validation: uncovered → JSON → parsed → == original.
 
 #### Ensure LLM Usability
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
index b143be6..ad98c18 100644
--- a/src/showcov/cli.py
+++ b/src/showcov/cli.py
@@ -1,4 +1,5 @@
 import argparse
+import json
 import logging
 import operator
 import sys
@@ -9,6 +10,7 @@ from colorama import Fore, Style
 from colorama import init as colorama_init
 from defusedxml import ElementTree
 
+from . import __version__
 from .core import (
     CoverageXMLNotFoundError,
     determine_xml_file,
@@ -56,6 +58,12 @@ def parse_args() -> argparse.Namespace:
         action="store_true",
         help="Disable ANSI color codes in output",
     )
+    parser.add_argument(
+        "--format",
+        choices=("human", "json"),
+        default="human",
+        help="Output format",
+    )
     return parser.parse_args()
 
 
@@ -96,10 +104,25 @@ def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
             print()
 
 
+def print_json_output(uncovered: dict[Path, list[int]]) -> None:
+    """Print uncovered sections in JSON format."""
+    data: dict[str, object] = {"version": __version__, "files": []}
+    files: list[dict[str, object]] = []
+    for filename in sorted(uncovered.keys(), key=lambda p: p.resolve().as_posix()):
+        normalized = filename.resolve().as_posix()
+        lines_sorted = sorted(uncovered[filename])
+        groups = group_consecutive_numbers(lines_sorted)
+        groups = sorted(groups, key=operator.itemgetter(0))
+        ranges = [{"start": grp[0], "end": grp[-1]} for grp in groups]
+        files.append({"file": normalized, "uncovered": ranges})
+    data["files"] = files
+    print(json.dumps(data, indent=2, sort_keys=True))
+
+
 def main() -> None:
     """Entry point for the script."""
     args = parse_args()
-    if args.no_color:
+    if args.no_color or args.format == "json":
         disable_colors()
     try:
         xml_file: Path = determine_xml_file(args.xml_file)
@@ -121,10 +144,16 @@ def main() -> None:
     uncovered = gather_uncovered_lines(cast("Element", root))
 
     if not uncovered:
-        print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
+        if args.format == "json":
+            print_json_output({})
+        else:
+            print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
         return
 
-    print_uncovered_sections(uncovered)
+    if args.format == "json":
+        print_json_output(uncovered)
+    else:
+        print_uncovered_sections(uncovered)
 
 
 if __name__ == "__main__":
diff --git a/src/showcov/core.py b/src/showcov/core.py
index ec2482a..b58ad35 100644
--- a/src/showcov/core.py
+++ b/src/showcov/core.py
@@ -89,11 +89,11 @@ def determine_xml_file(xml_file: Namespace | None = None) -> Path:
         xml_file = xml_file.xml_file
 
     if xml_file:
-        return Path(xml_file)
+        return Path(xml_file).resolve()
 
     config_xml = get_config_xml_file()
     if config_xml:
-        return Path(config_xml)
+        return Path(config_xml).resolve()
 
     msg = "No coverage XML file specified or found in configuration."
     raise CoverageXMLNotFoundError(msg)
diff --git a/tests/test_cli.py b/tests/test_cli.py
index e69de29..0fdb2a5 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -0,0 +1,79 @@
+import json
+import sys
+from pathlib import Path
+
+from _pytest.capture import CaptureFixture
+from _pytest.monkeypatch import MonkeyPatch
+
+from showcov.cli import main, print_json_output
+
+
+def test_print_json_output(tmp_path: Path, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("print('hi')\n")
+    uncovered = {source_file: [1, 2, 4]}
+    print_json_output(uncovered)
+    captured = capsys.readouterr().out
+    assert "\x1b" not in captured
+    data = json.loads(captured)
+    assert data["files"][0]["file"] == source_file.resolve().as_posix()
+    assert data["files"][0]["uncovered"] == [
+        {"start": 1, "end": 2},
+        {"start": 4, "end": 4},
+    ]
+
+
+def test_main_json_output(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("print('hi')\n")
+    xml_content = f"""
+        <coverage>
+          <packages>
+            <package>
+              <classes>
+                <class filename=\"{source_file}\">
+                  <lines>
+                    <line number=\"1\" hits=\"0\"/>
+                  </lines>
+                </class>
+              </classes>
+            </package>
+          </packages>
+        </coverage>
+    """
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    monkeypatch.setattr(sys, "argv", ["prog", str(xml_file), "--format", "json"])
+    main()
+    captured = capsys.readouterr().out
+    assert "\x1b" not in captured
+    data = json.loads(captured)
+    assert data["files"][0]["file"] == source_file.resolve().as_posix()
+    assert data["files"][0]["uncovered"] == [{"start": 1, "end": 1}]
+
+
+def test_main_json_output_no_uncovered(
+    tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture
+) -> None:
+    xml_content = """
+        <coverage>
+          <packages>
+            <package>
+              <classes>
+                <class filename=\"dummy.py\">
+                  <lines>
+                    <line number=\"1\" hits=\"1\"/>
+                  </lines>
+                </class>
+              </classes>
+            </package>
+          </packages>
+        </coverage>
+    """
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    monkeypatch.setattr(sys, "argv", ["prog", str(xml_file), "--format", "json"])
+    main()
+    captured = capsys.readouterr().out
+    data = json.loads(captured)
+    assert data["files"] == []
diff --git a/tests/test_core.py b/tests/test_core.py
index 36ff868..78f1f9a 100644
--- a/tests/test_core.py
+++ b/tests/test_core.py
@@ -71,14 +71,14 @@ def test_get_config_xml_file_pyproject(monkeypatch: MonkeyPatch, tmp_path: Path)
 def test_determine_xml_file_argument(monkeypatch: MonkeyPatch) -> None:
     test_args = ["prog", "coverage.xml"]
     monkeypatch.setattr(sys, "argv", test_args)
-    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml")
+    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml").resolve()
 
 
 def test_determine_xml_file_from_config(monkeypatch: MonkeyPatch) -> None:
     test_args = ["prog"]
     monkeypatch.setattr(sys, "argv", test_args)
     monkeypatch.setattr("showcov.core.get_config_xml_file", lambda: "coverage.xml")
-    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml")
+    assert determine_xml_file(argparse.Namespace(xml_file="coverage.xml")) == Path("coverage.xml").resolve()
 
 
 def test_determine_xml_file_no_args(monkeypatch: MonkeyPatch) -> None:
@@ -97,6 +97,7 @@ def test_parse_args_no_file(monkeypatch: MonkeyPatch) -> None:
     args = parse_args()
     assert args.xml_file is None
     assert args.no_color is False
+    assert args.format == "human"
 
 
 def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
@@ -105,6 +106,7 @@ def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
     args = parse_args()
     assert args.xml_file == "coverage.xml"
     assert args.no_color is False
+    assert args.format == "human"
 
 
 def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
@@ -112,6 +114,14 @@ def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
     assert args.no_color is True
+    assert args.format == "human"
+
+
+def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "--format", "json"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    args = parse_args()
+    assert args.format == "json"
 
 
 # --- Tests for `print_uncovered_sections` ---

f7f3194cae205f1c1e543381c41cadf32d1eb898 2025-08-02T12:17:48-04:00
79fa6f8048741b4f68171b06d0aa45c6daaf0126 2025-08-02T12:21:23-04:00---
 TODO.md        | 3 ++-
 pyproject.toml | 2 +-
 2 files changed, 3 insertions(+), 2 deletions(-)

diff --git a/TODO.md b/TODO.md
index d337a7a..73aee75 100644
--- a/TODO.md
+++ b/TODO.md
@@ -8,9 +8,10 @@
 
 #### Implement JSON Output
 
-* [ ] Assess the proposed JSON schema in the appendix for suitability.
 * [x] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
+* [ ] Add `--with-code` (optional): include source lines in the output.
 * [ ] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
+* [ ] Assess the JSON schema and update it as necessary.
 * [ ] Validate generated JSON matches schema using a static schema or runtime validator.
 
 ### II. LLM-Focused Enhancements
diff --git a/pyproject.toml b/pyproject.toml
index 83e9bd3..ce333be 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,7 +1,7 @@
 # =================================== project ====================================
 [project]
   name = "showcov"
-  version = "0.0.1"
+  version = "0.0.2"
   description = "Print out uncovered code."
   readme = "README.md"
   authors = [

1334916b7be174e89731f9e87db55f172920d86b 2025-08-02T12:36:12-04:00---
 TODO.md                      | 153 +++++++++----------------------------------
 src/showcov/data/schema.json |  66 +++++++++++++++++++
 2 files changed, 97 insertions(+), 122 deletions(-)

diff --git a/TODO.md b/TODO.md
index 73aee75..8d52b74 100644
--- a/TODO.md
+++ b/TODO.md
@@ -1,139 +1,48 @@
-### I. Output Format Refactor
-
-#### Add Output Format Option
+### Phase 1: Structured JSON Output with Schema and Options
 
+* [ ] Define `UncoveredSection(file: Path, ranges: list[tuple[int, int]])` model with `.to_dict()` for JSON export.
 * [x] Add CLI option `--format {human,json}` (default: `human`).
 * [x] Modify `main()` and `print_uncovered_sections()` to dispatch based on format.
-* [ ] Abstract uncovered data into a structured internal model before formatting.
-
-#### Implement JSON Output
-
 * [x] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
-* [ ] Add `--with-code` (optional): include source lines in the output.
+* [ ] Abstract uncovered data into the structured internal model before formatting.
 * [ ] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
-* [ ] Assess the JSON schema and update it as necessary.
+* [x] Assess the JSON schema (`src/showcov/data/schema.json`) and update it as necessary.
+* [ ] Ensure that `schema.json` file is included when packaging.
 * [ ] Validate generated JSON matches schema using a static schema or runtime validator.
+* [ ] Ensure path normalize to POSIX-style (`/`) and resolve paths relative to project root.
+* [x] Update/add tests covering:
 
-### II. LLM-Focused Enhancements
-
-#### Machine-Friendliness
-
-* [x] add a --no-color flag
-* [x] Remove all ANSI color codes and text styling from `json` mode.
-* [x] Normalize all paths to POSIX-style (`/`) and resolve relative paths.
-
-#### Determinism and Consistency
-
-* [x] Ensure stable ordering: files sorted alphabetically, uncovered groups ordered numerically.
-* [ ] Avoid floating or system-dependent fields (timestamps, random hashes, etc.).
-
-#### Contextual Source Embedding (optional future support)
-
-* [ ] Add option `--embed-source` to include raw source lines under each uncovered range:
-
-  ```json
-  { "start": 136, "end": 136, "lines": ["    return groups"] }
-  ```
-
-### III. Internal Architecture Improvements
+  * [x] JSON output structure using the model.
+  * [x] Presence/absence of code with `--with-code` and context lines.
+  * [ ] Schema validation success/failure.
+  * [x] No ANSI escape codes in JSON.
+  * [x] Stable ordering of files and ranges.
 
-#### Abstract Internal Data Model
-
-* [ ] Define `UncoveredSection(file: Path, ranges: list[tuple[int, int]])`.
-* [ ] Add model serialization methods: `.to_dict()` for JSON export.
-
-#### Decouple Output from Logic
+### Phase 2: Decouple formatting/output from Logic
 
 * [ ] Move all printing/formatting into dedicated module: `showcov/output.py`.
-* [ ] Allow output selection via a registry or strategy pattern.
-
-### IV. Protocol/Tooling Integration Readiness
+* [ ] Introduce output selection via a registry or strategy pattern so `--format` selects formatter.
+* [ ] Update `main()` to call into the new output layer via a clean API, passing model instances.
+* [ ] Ensure the human formatter still honors `--no-color` and that JSON formatter remains colorless.
+* [ ] Add tests for the new output module (unit tests invoking formatters with deterministic input).
 
-#### Context Protocol Support
+### Phase 3: Feature Completion and Determinism Guarantees (LLM Usability focus)
 
-* [ ] Design output to conform to emerging context-tool protocols (e.g. OpenAI tool-calling, LangChain toolkits).
-* [ ] Ensure that output JSON is valid with `application/json` MIME type, no extra preamble or wrapper.
+* [ ] Add option `--embed-source` to include raw source lines under each uncovered range.
+* [ ] Avoid floating or system-dependent fields (timestamps, random hashes, etc.) in all outputs.
+* [x] Ensure stable sorting: files alphabetically by posix path, uncovered groups ordered numerically, as invariants.
+* [ ] Ensure all JSON output fully complies with machine-friendly constraints (no ANSI in non-human modes, consistent structure).
+* [ ] Design output to conform to emerging context-tool protocols (e.g. OpenAI tool-calling, LangChain toolkits) as needed.
 
-#### CLI + API Parity
+### Phase 4: Testing Enhancements beyond Basic Correctness
 
-* [x] Expose main logic as a function callable via API:
-  `get_coverage_data(xml_path: Path) -> list[UncoveredSection]`
+* [ ] Add round-trip validation: uncovered → JSON → parsed → == original model instances.
+* [ ] Add snapshot tests of JSON output and sample prompts to LLMs for smoke-checking usability.
+* [ ] Expand coverage for edge/corner cases introduced by new features (missing source files when embedding, invalid context ranges, etc.).
 
-#### JSON Schema + Type Hints
+### Phase 5: Protocol/tooling Integration Readiness
 
-* [ ] Provide a `schema.json` file for the JSON output format.
+* [ ] Ensure output JSON is valid with `application/json` MIME type, no extra preamble or wrapper.
+* [ ] Expose main logic as a function callable via API: `get_coverage_data(xml_path: Path) -> list[UncoveredSection]` (already done but ensure documentation and tests).
 * [ ] Annotate output functions with complete type hints using `TypedDict` or `pydantic.BaseModel`.
-
-### V. Testing Enhancements
-
-#### Add Format-Specific Tests
-
-* [x] Add tests for `--format json` using `json.loads` and structural assertions.
-* [ ] Add round-trip validation: uncovered → JSON → parsed → == original.
-
-#### Ensure LLM Usability
-
-* [ ] Add snapshot tests of JSON output and sample prompts to LLMs for smoke-checking usability.
-
-## Appendix
-### Proposed JSON Schema
-```json
-```json
-{
-  "$schema": "https://json-schema.org/draft/2020-12/schema",
-  "$id": "https://example.com/showcov.schema.json",
-  "title": "Showcov Coverage Report",
-  "type": "object",
-  "properties": {
-    "version": {
-      "description": "Version of the showcov tool or schema.",
-      "type": "string",
-      "pattern": "^\\d+\\.\\d+\\.\\d+$"
-    },
-    "files": {
-      "description": "List of source files with uncovered code sections.",
-      "type": "array",
-      "items": {
-        "type": "object",
-        "properties": {
-          "file": {
-            "description": "Path to the source file.",
-            "type": "string"
-          },
-          "uncovered": {
-            "description": "List of uncovered line ranges.",
-            "type": "array",
-            "items": {
-              "type": "object",
-              "properties": {
-                "start": {
-                  "type": "integer",
-                  "minimum": 1
-                },
-                "end": {
-                  "type": "integer",
-                  "minimum": 1
-                },
-                "lines": {
-                  "description": "Optional source code lines in this range.",
-                  "type": "array",
-                  "items": {
-                    "type": "string"
-                  },
-                  "minItems": 1
-                }
-              },
-              "required": ["start", "end"],
-              "additionalProperties": false
-            }
-          }
-        },
-        "required": ["file", "uncovered"],
-        "additionalProperties": false
-      }
-    }
-  },
-  "required": ["version", "files"],
-  "additionalProperties": false
-}
-```
+* [ ] Ensure public API and output are documented for CLI/API parity and external tooling consumption.
diff --git a/src/showcov/data/schema.json b/src/showcov/data/schema.json
new file mode 100644
index 0000000..017857e
--- /dev/null
+++ b/src/showcov/data/schema.json
@@ -0,0 +1,66 @@
+{
+  "$schema": "https://json-schema.org/draft/2020-12/schema",
+  "$id": "https://example.com/showcov.schema.json",
+  "title": "Showcov Coverage Report",
+  "type": "object",
+  "properties": {
+    "version": {
+      "description": "Version of the showcov tool or schema.",
+      "type": "string",
+      "pattern": "^\\d+\\.\\d+\\.\\d+$"
+    },
+    "files": {
+      "description": "List of source files with uncovered code sections.",
+      "type": "array",
+      "items": {
+        "type": "object",
+        "properties": {
+          "file": {
+            "description": "Path to the source file.",
+            "type": "string"
+          },
+          "uncovered": {
+            "description": "List of uncovered line ranges.",
+            "type": "array",
+            "items": {
+              "type": "object",
+              "properties": {
+                "start": {
+                  "type": "integer",
+                  "minimum": 1
+                },
+                "end": {
+                  "type": "integer",
+                  "minimum": 1
+                },
+                "lines": {
+                  "description": "Optional source code lines in this range.",
+                  "type": "array",
+                  "items": {
+                    "type": "string"
+                  },
+                  "minItems": 1
+                }
+              },
+              "required": [
+                "start",
+                "end"
+              ],
+              "additionalProperties": false
+            }
+          }
+        },
+        "required": [
+          "file",
+          "uncovered"
+        ],
+        "additionalProperties": false
+      }
+    }
+  },
+  "required": [
+    "version",
+    "files"
+  ],
+  "additionalProperties": false
+}

aea34a5f81a93c6790ebc02323a5ede33d5f8758 2025-08-02T12:50:24-04:00---
 pyproject.toml          |   6 +++
 src/showcov/__init__.py |   7 +++-
 src/showcov/cli.py      | 102 +++++++++++++++++++++++++++---------------------
 src/showcov/core.py     |  83 ++++++++++++++++++++++++++++++++++++++-
 tests/test_cli.py       |  43 +++++++++++++++++++-
 tests/test_core.py      |  28 +++++--------
 6 files changed, 201 insertions(+), 68 deletions(-)

diff --git a/pyproject.toml b/pyproject.toml
index ce333be..35f1b13 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -20,6 +20,7 @@
     "colorama>=0.4.6",
     "configparser>=7.1.0",
     "defusedxml>=0.7.1",
+    "jsonschema>=4.23.0",  # Runtime JSON schema validation
   ]
 
   [project.scripts]
@@ -36,6 +37,7 @@
     "types-colorama>=0.4.15.20240311",
     "types-defusedxml>=0.7.0.20240218",
     "types-toml>=0.10.8.20240310",
+    "types-jsonschema>=4.23.0.20240712",
   ]
 
 # =================================== build ====================================
@@ -43,6 +45,9 @@
   requires      = ["uv_build>=0.6,<0.7"]
   build-backend = "uv_build"
 
+[tool.uv_build]
+  resources = ["showcov/data/schema.json"]
+
 
 # ==================================== lint ====================================
 [tool.ruff]
@@ -62,6 +67,7 @@
   pythonPlatform = "Darwin"
   reportImplicitOverride = false
   reportMissingTypeStubs = false
+  reportMissingImports = false
   reportUnusedParameter = false
   executionEnvironments = [
     { root = "tests", reportPrivateUsage = false, reportUnusedCallResult = false, extraPaths = [] },
diff --git a/src/showcov/__init__.py b/src/showcov/__init__.py
index 1e50d83..594e963 100644
--- a/src/showcov/__init__.py
+++ b/src/showcov/__init__.py
@@ -1,5 +1,8 @@
-from importlib.metadata import version
+from importlib.metadata import PackageNotFoundError, version
 
 __all__ = ["__version__"]
 
-__version__ = version("showcov")
+try:
+    __version__ = version("showcov")
+except PackageNotFoundError:  # pragma: no cover - fallback for src layout
+    __version__ = "0.0.0"
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
index ad98c18..f543022 100644
--- a/src/showcov/cli.py
+++ b/src/showcov/cli.py
@@ -1,25 +1,29 @@
 import argparse
 import json
 import logging
-import operator
 import sys
+from importlib import resources
 from pathlib import Path
 from typing import TYPE_CHECKING, cast
 
 from colorama import Fore, Style
 from colorama import init as colorama_init
 from defusedxml import ElementTree
+from jsonschema import validate
 
 from . import __version__
 from .core import (
     CoverageXMLNotFoundError,
+    UncoveredSection,
+    build_sections,
     determine_xml_file,
     gather_uncovered_lines,
-    group_consecutive_numbers,
-    merge_blank_gap_groups,
     parse_large_xml,
 )
 
+# Load JSON schema once
+SCHEMA = json.loads(resources.files("showcov.data").joinpath("schema.json").read_text(encoding="utf-8"))
+
 # Initialize colorama
 colorama_init(autoreset=True)
 
@@ -35,9 +39,6 @@ MAGENTA = Fore.MAGENTA
 GREEN = Fore.GREEN
 RED = Fore.RED
 
-# Constants
-CONSECUTIVE_STEP = 1
-
 # Configure logging
 logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
 logger = logging.getLogger(__name__)
@@ -58,6 +59,17 @@ def parse_args() -> argparse.Namespace:
         action="store_true",
         help="Disable ANSI color codes in output",
     )
+    parser.add_argument(
+        "--with-code",
+        action="store_true",
+        help="Include source code lines in JSON output",
+    )
+    parser.add_argument(
+        "--context-lines",
+        type=int,
+        default=0,
+        help="Number of context lines to include around uncovered sections",
+    )
     parser.add_argument(
         "--format",
         choices=("human", "json"),
@@ -67,55 +79,54 @@ def parse_args() -> argparse.Namespace:
     return parser.parse_args()
 
 
-def print_uncovered_sections(uncovered: dict[Path, list[int]]) -> None:
+def print_uncovered_sections(sections: list[UncoveredSection], *, context_lines: int) -> None:
     """Print uncovered sections from files."""
-    for filename in sorted(uncovered.keys(), key=lambda p: p.as_posix()):
-        lines_sorted = sorted(uncovered[filename])
-        groups = group_consecutive_numbers(lines_sorted)
-        groups = sorted(groups, key=operator.itemgetter(0))
-        print(f"\n{BOLD}{YELLOW}Uncovered sections in {filename.as_posix()}:{RESET}")
+    root = Path.cwd().resolve()
+    for section in sections:
+        try:
+            rel = section.file.resolve().relative_to(root)
+        except ValueError:
+            rel = section.file.resolve()
+        print(f"\n{BOLD}{YELLOW}Uncovered sections in {rel.as_posix()}:{RESET}")
 
         try:
-            with filename.open(encoding="utf-8") as f:
-                file_lines = f.readlines()
-            groups = merge_blank_gap_groups(groups, file_lines)
+            with section.file.open(encoding="utf-8") as f:
+                file_lines = [ln.rstrip("\n") for ln in f.readlines()]
         except OSError:
-            logger.exception("Could not open %s", filename)
-            for grp in groups:
-                print(
-                    f"  {CYAN}Lines {grp[0]}-{grp[-1]}{RESET}"
-                    if len(grp) > 1
-                    else f"  {CYAN}Line {grp[0]}{RESET}"
+            logger.exception("Could not open %s", section.file)
+            for start, end in section.ranges:
+                text = (
+                    f"  {CYAN}Lines {start}-{end}{RESET}" if start != end else f"  {CYAN}Line {start}{RESET}"
                 )
+                print(text)
             continue
 
-        for grp in groups:
+        for start, end in section.ranges:
             header = (
-                f"  {BOLD}{CYAN}Lines {grp[0]}-{grp[-1]}:{RESET}"
-                if len(grp) > 1
-                else f"  {BOLD}{CYAN}Line {grp[0]}:{RESET}"
+                f"  {BOLD}{CYAN}Lines {start}-{end}:{RESET}"
+                if start != end
+                else f"  {BOLD}{CYAN}Line {start}:{RESET}"
             )
             print(header)
-            for ln in grp:
-                content = (
-                    file_lines[ln - 1].rstrip("\n") if 1 <= ln <= len(file_lines) else "<line not found>"
-                )
-                print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
+            start_idx = max(1, start - context_lines)
+            end_idx = min(len(file_lines), end + context_lines)
+            for ln in range(start_idx, end_idx + 1):
+                content = file_lines[ln - 1] if 1 <= ln <= len(file_lines) else "<line not found>"
+                if start <= ln <= end:
+                    print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
+                else:
+                    print(f"    {ln:4d}: {content}")
             print()
 
 
-def print_json_output(uncovered: dict[Path, list[int]]) -> None:
+def print_json_output(sections: list[UncoveredSection], *, with_code: bool, context_lines: int) -> None:
     """Print uncovered sections in JSON format."""
-    data: dict[str, object] = {"version": __version__, "files": []}
-    files: list[dict[str, object]] = []
-    for filename in sorted(uncovered.keys(), key=lambda p: p.resolve().as_posix()):
-        normalized = filename.resolve().as_posix()
-        lines_sorted = sorted(uncovered[filename])
-        groups = group_consecutive_numbers(lines_sorted)
-        groups = sorted(groups, key=operator.itemgetter(0))
-        ranges = [{"start": grp[0], "end": grp[-1]} for grp in groups]
-        files.append({"file": normalized, "uncovered": ranges})
-    data["files"] = files
+    data: dict[str, object] = {
+        "version": __version__,
+        "files": [sec.to_dict(with_code=with_code, context_lines=context_lines) for sec in sections],
+    }
+
+    validate(data, SCHEMA)
     print(json.dumps(data, indent=2, sort_keys=True))
 
 
@@ -142,18 +153,19 @@ def main() -> None:
         sys.exit(1)
 
     uncovered = gather_uncovered_lines(cast("Element", root))
+    sections = build_sections(uncovered)
 
-    if not uncovered:
+    if not sections:
         if args.format == "json":
-            print_json_output({})
+            print_json_output([], with_code=args.with_code, context_lines=args.context_lines)
         else:
             print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
         return
 
     if args.format == "json":
-        print_json_output(uncovered)
+        print_json_output(sections, with_code=args.with_code, context_lines=args.context_lines)
     else:
-        print_uncovered_sections(uncovered)
+        print_uncovered_sections(sections, context_lines=args.context_lines)
 
 
 if __name__ == "__main__":
diff --git a/src/showcov/core.py b/src/showcov/core.py
index b58ad35..272e13a 100644
--- a/src/showcov/core.py
+++ b/src/showcov/core.py
@@ -6,10 +6,12 @@ a configuration file (pyproject.toml, .coveragerc, or setup.cfg).
 """
 
 import logging
+import operator
 import tomllib
 from argparse import Namespace
 from configparser import ConfigParser
 from configparser import Error as ConfigError
+from dataclasses import dataclass
 from pathlib import Path
 from typing import TYPE_CHECKING, Optional
 
@@ -31,6 +33,66 @@ class CoverageXMLNotFoundError(Exception):
     """Coverage XML file not found."""
 
 
+@dataclass(slots=True)
+class UncoveredSection:
+    """Structured representation of uncovered code for a single file.
+
+    Parameters
+    ----------
+    file:
+        Path to the source file.
+    ranges:
+        List of ``(start, end)`` tuples representing uncovered line ranges.
+    """
+
+    file: Path
+    ranges: list[tuple[int, int]]
+
+    def to_dict(self, *, with_code: bool = False, context_lines: int = 0) -> dict[str, object]:
+        """Convert the section into a JSON-serialisable dictionary.
+
+        Parameters
+        ----------
+        with_code:
+            Include source code lines within each uncovered range. When
+            ``context_lines`` is greater than zero, the returned lines will
+            also include that many lines of surrounding context.
+        context_lines:
+            Number of context lines to include before and after each uncovered
+            range when ``with_code`` is ``True``.
+        """
+        root = Path.cwd().resolve()
+        try:
+            path = self.file.resolve().relative_to(root)
+        except ValueError:
+            path = self.file.resolve()
+        file_str = path.as_posix()
+
+        uncovered_entries: list[dict[str, object]] = []
+
+        file_lines: list[str] = []
+        if with_code:
+            try:
+                with self.file.open(encoding="utf-8") as f:
+                    file_lines = [ln.rstrip("\n") for ln in f.readlines()]
+            except OSError:
+                file_lines = []
+
+        for start, end in self.ranges:
+            entry: dict[str, object] = {"start": start, "end": end}
+            if with_code and file_lines:
+                start_idx = max(1, start - context_lines)
+                end_idx = min(len(file_lines), end + context_lines)
+                lines = [
+                    file_lines[i - 1] if 1 <= i <= len(file_lines) else "<line not found>"
+                    for i in range(start_idx, end_idx + 1)
+                ]
+                entry["lines"] = lines
+            uncovered_entries.append(entry)
+
+        return {"file": file_str, "uncovered": uncovered_entries}
+
+
 def _get_xml_from_config(config_path: Path, section: str, option: str) -> str | None:
     """Extract an XML path from the configuration file."""
     config = ConfigParser()
@@ -126,7 +188,9 @@ def merge_blank_gap_groups(groups: list[list[int]], file_lines: list[str]) -> li
         gap_start = last_grp[-1] + 1
         gap_end = grp[0] - 1
 
-        if gap_start <= gap_end and all(not file_lines[i - 1].strip() for i in range(gap_start, gap_end + 1)):
+        if gap_start <= gap_end and all(
+            i - 1 < len(file_lines) and not file_lines[i - 1].strip() for i in range(gap_start, gap_end + 1)
+        ):
             merged[-1].extend(grp)
         else:
             merged.append(grp)
@@ -167,6 +231,23 @@ def gather_uncovered_lines(root: "Element") -> dict[Path, list[int]]:
     return uncovered
 
 
+def build_sections(uncovered: dict[Path, list[int]]) -> list[UncoveredSection]:
+    """Convert mapping of uncovered line numbers to structured sections."""
+    sections: list[UncoveredSection] = []
+    for filename in sorted(uncovered.keys(), key=lambda p: p.as_posix()):
+        lines_sorted = sorted(uncovered[filename])
+        groups = group_consecutive_numbers(lines_sorted)
+        try:
+            with filename.open(encoding="utf-8") as f:
+                file_lines = f.readlines()
+            groups = merge_blank_gap_groups(groups, file_lines)
+        except OSError:
+            pass
+        ranges = [(grp[0], grp[-1]) for grp in sorted(groups, key=operator.itemgetter(0))]
+        sections.append(UncoveredSection(filename, ranges))
+    return sections
+
+
 def parse_large_xml(file_path: Path) -> Optional["Element"]:
     """Efficiently parse large XML files with iterparse."""
     context = ElementTree.iterparse(file_path, events=("start", "end"))
diff --git a/tests/test_cli.py b/tests/test_cli.py
index 0fdb2a5..7779f58 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -1,18 +1,23 @@
 import json
 import sys
+from importlib import resources
 from pathlib import Path
 
+import pytest
 from _pytest.capture import CaptureFixture
 from _pytest.monkeypatch import MonkeyPatch
+from jsonschema import ValidationError, validate
 
+from showcov import __version__
 from showcov.cli import main, print_json_output
+from showcov.core import build_sections
 
 
 def test_print_json_output(tmp_path: Path, capsys: CaptureFixture) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("print('hi')\n")
-    uncovered = {source_file: [1, 2, 4]}
-    print_json_output(uncovered)
+    sections = build_sections({source_file: [1, 2, 4]})
+    print_json_output(sections, with_code=False, context_lines=0)
     captured = capsys.readouterr().out
     assert "\x1b" not in captured
     data = json.loads(captured)
@@ -77,3 +82,37 @@ def test_main_json_output_no_uncovered(
     captured = capsys.readouterr().out
     data = json.loads(captured)
     assert data["files"] == []
+
+
+def test_print_json_output_with_code_and_context(tmp_path: Path, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("a\nb\nc\n")
+    sections = build_sections({source_file: [2]})
+    print_json_output(sections, with_code=True, context_lines=1)
+    data = json.loads(capsys.readouterr().out)
+    assert data["files"][0]["uncovered"][0]["lines"] == ["a", "b", "c"]
+
+
+def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("print('hi')\n")
+    sections = build_sections({source_file: [1]})
+    print_json_output(sections, with_code=True, context_lines=0)
+    data = json.loads(capsys.readouterr().out)
+    schema = json.loads(resources.files("showcov.data").joinpath("schema.json").read_text(encoding="utf-8"))
+    validate(data, schema)
+    bad = {"version": __version__, "files": [{"file": "x", "uncovered": [{"start": "a", "end": 2}]}]}
+    with pytest.raises(ValidationError):
+        validate(bad, schema)
+
+
+def test_print_json_output_relative_path(
+    tmp_path: Path, capsys: CaptureFixture, monkeypatch: MonkeyPatch
+) -> None:
+    monkeypatch.chdir(tmp_path)
+    source_file = Path("dummy.py")
+    source_file.write_text("print('hi')\n", encoding="utf-8")
+    sections = build_sections({source_file: [1]})
+    print_json_output(sections, with_code=False, context_lines=0)
+    data = json.loads(capsys.readouterr().out)
+    assert data["files"][0]["file"] == "dummy.py"
diff --git a/tests/test_core.py b/tests/test_core.py
index 78f1f9a..90f9815 100644
--- a/tests/test_core.py
+++ b/tests/test_core.py
@@ -22,6 +22,7 @@ from showcov.core import (
     CoverageXMLNotFoundError,
     _get_xml_from_config,
     _get_xml_from_pyproject,
+    build_sections,
     determine_xml_file,
     gather_uncovered_lines,
     get_config_xml_file,
@@ -130,8 +131,8 @@ def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
 def test_print_uncovered_sections(tmp_path: Path, capsys: CaptureFixture) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("def foo():\n    pass\n\ndef bar():\n    return 42")
-    uncovered = {source_file: [2, 4, 5]}
-    print_uncovered_sections(uncovered)
+    sections = build_sections({source_file: [2, 4, 5]})
+    print_uncovered_sections(sections, context_lines=0)
     captured = capsys.readouterr().out
     assert "Uncovered sections in" in captured
     assert "Line" in captured
@@ -143,9 +144,9 @@ def test_print_uncovered_sections(tmp_path: Path, capsys: CaptureFixture) -> Non
 def test_print_uncovered_sections_no_color(tmp_path: Path, capsys: CaptureFixture) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("print('hi')\n")
-    uncovered = {source_file: [1]}
+    sections = build_sections({source_file: [1]})
     disable_colors()
-    print_uncovered_sections(uncovered)
+    print_uncovered_sections(sections, context_lines=0)
     captured = capsys.readouterr().out
     assert "\x1b" not in captured
 
@@ -155,8 +156,8 @@ def test_print_uncovered_sections_sorted_files(tmp_path: Path, capsys: CaptureFi
     file_a = tmp_path / "a.py"
     file_a.write_text("a=1\n")
     file_b.write_text("b=1\n")
-    uncovered = {file_b: [1], file_a: [1]}
-    print_uncovered_sections(uncovered)
+    sections = build_sections({file_b: [1], file_a: [1]})
+    print_uncovered_sections(sections, context_lines=0)
     captured = capsys.readouterr().out
     first = captured.find(file_a.as_posix())
     second = captured.find(file_b.as_posix())
@@ -387,19 +388,10 @@ def test_merge_blank_gap_groups_no_merge():
 # --- Test for print_uncovered_sections exception branch (lines 163-166, 171) ---
 
 
-def test_print_uncovered_sections_file_open_error(monkeypatch, capsys, tmp_path):
+def test_print_uncovered_sections_file_open_error(capsys, tmp_path):
     fake_file = tmp_path / "nonexistent.py"
-    uncovered = {fake_file: [1, 2]}
-
-    # Simulate an OSError when trying to open a source file. The function should catch the exception,
-    # log the error, and still print the grouped line numbers.
-    def fake_open(*args, **kwargs):
-        msg = "simulated file open error"
-        raise OSError(msg)
-
-    # Monkey-patch the open() method on the Path object.
-    monkeypatch.setattr(Path, "open", fake_open)
-    print_uncovered_sections(uncovered)
+    sections = build_sections({fake_file: [1, 2]})
+    print_uncovered_sections(sections, context_lines=0)
     captured = capsys.readouterr().out
     assert "Uncovered sections in" in captured
     assert "Line" in captured

7418f0108664b747282196bee3c01518b35ca4da 2025-08-02T12:50:47-04:00
5a8cfc1ae1f1aaedefd298d44495f1762c7d838f 2025-08-02T12:50:56-04:00
5182a4fb6042e1d2137fddbb6256273b2373251e 2025-08-02T12:50:56-04:00
336cbf94a1d4b8d6aa3706fd8e04d2aa4d54f8f0 2025-08-02T12:54:17-04:00---
 .grobl.config.json |  1 -
 TODO.md            | 14 +++++++-------
 pyproject.toml     |  2 +-
 3 files changed, 8 insertions(+), 9 deletions(-)

diff --git a/.grobl.config.json b/.grobl.config.json
index 3e7e1b3..f2d161c 100644
--- a/.grobl.config.json
+++ b/.grobl.config.json
@@ -19,7 +19,6 @@
     "yarn.lock"
   ],
   "exclude_print": [
-    "*.json",
     "*.html"
   ],
   "include_tree_tags": "tree",
diff --git a/TODO.md b/TODO.md
index 8d52b74..8836cf7 100644
--- a/TODO.md
+++ b/TODO.md
@@ -1,20 +1,20 @@
 ### Phase 1: Structured JSON Output with Schema and Options
 
-* [ ] Define `UncoveredSection(file: Path, ranges: list[tuple[int, int]])` model with `.to_dict()` for JSON export.
+* [x] Define `UncoveredSection(file: Path, ranges: list[tuple[int, int]])` model with `.to_dict()` for JSON export.
 * [x] Add CLI option `--format {human,json}` (default: `human`).
 * [x] Modify `main()` and `print_uncovered_sections()` to dispatch based on format.
 * [x] Write `print_json_output(uncovered_data: dict[Path, list[int]]) -> None`.
-* [ ] Abstract uncovered data into the structured internal model before formatting.
-* [ ] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
+* [x] Abstract uncovered data into the structured internal model before formatting.
+* [x] Add `--context-lines=N` (optional): include source lines ±N around each uncovered section.
 * [x] Assess the JSON schema (`src/showcov/data/schema.json`) and update it as necessary.
-* [ ] Ensure that `schema.json` file is included when packaging.
-* [ ] Validate generated JSON matches schema using a static schema or runtime validator.
-* [ ] Ensure path normalize to POSIX-style (`/`) and resolve paths relative to project root.
+* [x] Ensure that `schema.json` file is included when packaging.
+* [x] Validate generated JSON matches schema using a static schema or runtime validator.
+* [x] Ensure path normalize to POSIX-style (`/`) and resolve paths relative to project root.
 * [x] Update/add tests covering:
 
   * [x] JSON output structure using the model.
   * [x] Presence/absence of code with `--with-code` and context lines.
-  * [ ] Schema validation success/failure.
+  * [x] Schema validation success/failure.
   * [x] No ANSI escape codes in JSON.
   * [x] Stable ordering of files and ranges.
 
diff --git a/pyproject.toml b/pyproject.toml
index 35f1b13..4cf6a7f 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,7 +1,7 @@
 # =================================== project ====================================
 [project]
   name = "showcov"
-  version = "0.0.2"
+  version = "0.0.3"
   description = "Print out uncovered code."
   readme = "README.md"
   authors = [

69392d0e3114c49209f290efe56d88988fc67428 2025-08-02T12:57:51-04:00---
 TODO.md | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/TODO.md b/TODO.md
index 8836cf7..d06ebee 100644
--- a/TODO.md
+++ b/TODO.md
@@ -20,6 +20,8 @@
 
 ### Phase 2: Decouple formatting/output from Logic
 
+* [ ] Add an item to the JSON output (and update the schema) to indicate the "environment" like what coverage file was run, and other important details.
+* [ ] Make the behavior with respect to different command line flags consistent across output formats.
 * [ ] Move all printing/formatting into dedicated module: `showcov/output.py`.
 * [ ] Introduce output selection via a registry or strategy pattern so `--format` selects formatter.
 * [ ] Update `main()` to call into the new output layer via a clean API, passing model instances.

804c7f5e222b3a594f8bb07193f85d0f2b583da4 2025-08-02T13:05:39-04:00---
 AGENTS.md | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/AGENTS.md b/AGENTS.md
index b260e0e..76ee673 100644
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -46,6 +46,9 @@ You must use the following tools for validation and conformance before proposing
 - **Output stability**: sort all file paths and line groups deterministically.
 - **No ANSI styling** in non-human formats (e.g., JSON).
 - **No I/O outside of `src/`, `tests/`, or `TODO.md`** unless instructed.
+- **Maintain Code Quality During Development**: run linter, formatter, and type checker after editing code.
+- **Keep the User Updated**: While performing edits, if you have chat capability, write out status updates prefixed with "WORK STATUS: "
+- **Keep to do list up to date**: as items on the TODO.md list are finished, mark them as complete.
 
 ## Commit Standards
 
@@ -59,6 +62,8 @@ You must use the following tools for validation and conformance before proposing
   - `fix: handle missing <class> tag in coverage XML`
   - `test: add tests for merge_blank_gap_groups`
 
+- Bump the version in `pyproject.toml` as appropriate before pull requests.
+
 ## Prohibited
 
 - Do not introduce new dependencies without justification in a comment.

2842351da7d3f821e640d9612fac4f7686fbeeee 2025-08-02T13:07:51-04:00---
 TODO.md                      |  14 ++---
 pyproject.toml               |   2 +-
 src/showcov/cli.py           | 104 ++++-----------------------------
 src/showcov/data/schema.json |  12 ++++
 src/showcov/output.py        | 133 +++++++++++++++++++++++++++++++++++++++++++
 tests/test_cli.py            |  57 +++++++++++++------
 tests/test_core.py           |  77 +++++++++++++++----------
 tests/test_output.py         |  30 ++++++++++
 8 files changed, 281 insertions(+), 148 deletions(-)

diff --git a/TODO.md b/TODO.md
index d06ebee..c8eeeec 100644
--- a/TODO.md
+++ b/TODO.md
@@ -20,13 +20,13 @@
 
 ### Phase 2: Decouple formatting/output from Logic
 
-* [ ] Add an item to the JSON output (and update the schema) to indicate the "environment" like what coverage file was run, and other important details.
-* [ ] Make the behavior with respect to different command line flags consistent across output formats.
-* [ ] Move all printing/formatting into dedicated module: `showcov/output.py`.
-* [ ] Introduce output selection via a registry or strategy pattern so `--format` selects formatter.
-* [ ] Update `main()` to call into the new output layer via a clean API, passing model instances.
-* [ ] Ensure the human formatter still honors `--no-color` and that JSON formatter remains colorless.
-* [ ] Add tests for the new output module (unit tests invoking formatters with deterministic input).
+* [x] Add an item to the JSON output (and update the schema) to indicate the "environment" like what coverage file was run, and other important details.
+* [x] Make the behavior with respect to different command line flags consistent across output formats.
+* [x] Move all printing/formatting into dedicated module: `showcov/output.py`.
+* [x] Introduce output selection via a registry or strategy pattern so `--format` selects formatter.
+* [x] Update `main()` to call into the new output layer via a clean API, passing model instances.
+* [x] Ensure the human formatter still honors `--no-color` and that JSON formatter remains colorless.
+* [x] Add tests for the new output module (unit tests invoking formatters with deterministic input).
 
 ### Phase 3: Feature Completion and Determinism Guarantees (LLM Usability focus)
 
diff --git a/pyproject.toml b/pyproject.toml
index 4cf6a7f..5698dd3 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,7 +1,7 @@
 # =================================== project ====================================
 [project]
   name = "showcov"
-  version = "0.0.3"
+  version = "0.0.4"
   description = "Print out uncovered code."
   readme = "README.md"
   authors = [
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
index f543022..7419a43 100644
--- a/src/showcov/cli.py
+++ b/src/showcov/cli.py
@@ -1,55 +1,28 @@
 import argparse
-import json
 import logging
 import sys
-from importlib import resources
-from pathlib import Path
 from typing import TYPE_CHECKING, cast
 
-from colorama import Fore, Style
-from colorama import init as colorama_init
 from defusedxml import ElementTree
-from jsonschema import validate
 
-from . import __version__
 from .core import (
     CoverageXMLNotFoundError,
-    UncoveredSection,
     build_sections,
     determine_xml_file,
     gather_uncovered_lines,
     parse_large_xml,
 )
-
-# Load JSON schema once
-SCHEMA = json.loads(resources.files("showcov.data").joinpath("schema.json").read_text(encoding="utf-8"))
-
-# Initialize colorama
-colorama_init(autoreset=True)
+from .output import FORMATTERS
 
 if TYPE_CHECKING:
+    from pathlib import Path
     from xml.etree.ElementTree import Element  # noqa: S405
 
-# ANSI color codes (cross-platform)
-RESET = Style.RESET_ALL
-BOLD = Style.BRIGHT
-YELLOW = Fore.YELLOW
-CYAN = Fore.CYAN
-MAGENTA = Fore.MAGENTA
-GREEN = Fore.GREEN
-RED = Fore.RED
-
 # Configure logging
 logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
 logger = logging.getLogger(__name__)
 
 
-def disable_colors() -> None:
-    """Disable ANSI color codes."""
-    global RESET, BOLD, YELLOW, CYAN, MAGENTA, GREEN, RED  # noqa: PLW0603
-    RESET = BOLD = YELLOW = CYAN = MAGENTA = GREEN = RED = ""
-
-
 def parse_args() -> argparse.Namespace:
     """Parse command-line arguments."""
     parser = argparse.ArgumentParser(description="Show uncovered lines from a coverage XML report.")
@@ -79,62 +52,9 @@ def parse_args() -> argparse.Namespace:
     return parser.parse_args()
 
 
-def print_uncovered_sections(sections: list[UncoveredSection], *, context_lines: int) -> None:
-    """Print uncovered sections from files."""
-    root = Path.cwd().resolve()
-    for section in sections:
-        try:
-            rel = section.file.resolve().relative_to(root)
-        except ValueError:
-            rel = section.file.resolve()
-        print(f"\n{BOLD}{YELLOW}Uncovered sections in {rel.as_posix()}:{RESET}")
-
-        try:
-            with section.file.open(encoding="utf-8") as f:
-                file_lines = [ln.rstrip("\n") for ln in f.readlines()]
-        except OSError:
-            logger.exception("Could not open %s", section.file)
-            for start, end in section.ranges:
-                text = (
-                    f"  {CYAN}Lines {start}-{end}{RESET}" if start != end else f"  {CYAN}Line {start}{RESET}"
-                )
-                print(text)
-            continue
-
-        for start, end in section.ranges:
-            header = (
-                f"  {BOLD}{CYAN}Lines {start}-{end}:{RESET}"
-                if start != end
-                else f"  {BOLD}{CYAN}Line {start}:{RESET}"
-            )
-            print(header)
-            start_idx = max(1, start - context_lines)
-            end_idx = min(len(file_lines), end + context_lines)
-            for ln in range(start_idx, end_idx + 1):
-                content = file_lines[ln - 1] if 1 <= ln <= len(file_lines) else "<line not found>"
-                if start <= ln <= end:
-                    print(f"    {MAGENTA}{ln:4d}{RESET}: {content}")
-                else:
-                    print(f"    {ln:4d}: {content}")
-            print()
-
-
-def print_json_output(sections: list[UncoveredSection], *, with_code: bool, context_lines: int) -> None:
-    """Print uncovered sections in JSON format."""
-    data: dict[str, object] = {
-        "version": __version__,
-        "files": [sec.to_dict(with_code=with_code, context_lines=context_lines) for sec in sections],
-    }
-
-    validate(data, SCHEMA)
-    print(json.dumps(data, indent=2, sort_keys=True))
-
-
 def main() -> None:
     """Entry point for the script."""
     args = parse_args()
-    if args.no_color or args.format == "json":
-        disable_colors()
     try:
         xml_file: Path = determine_xml_file(args.xml_file)
     except CoverageXMLNotFoundError:
@@ -155,17 +75,15 @@ def main() -> None:
     uncovered = gather_uncovered_lines(cast("Element", root))
     sections = build_sections(uncovered)
 
-    if not sections:
-        if args.format == "json":
-            print_json_output([], with_code=args.with_code, context_lines=args.context_lines)
-        else:
-            print(f"{GREEN}{BOLD}No uncovered lines found!{RESET}")
-        return
-
-    if args.format == "json":
-        print_json_output(sections, with_code=args.with_code, context_lines=args.context_lines)
-    else:
-        print_uncovered_sections(sections, context_lines=args.context_lines)
+    formatter = FORMATTERS[args.format]
+    output = formatter(
+        sections,
+        context_lines=args.context_lines,
+        with_code=args.with_code,
+        coverage_xml=xml_file,
+        color=not args.no_color,
+    )
+    print(output)
 
 
 if __name__ == "__main__":
diff --git a/src/showcov/data/schema.json b/src/showcov/data/schema.json
index 017857e..db49e33 100644
--- a/src/showcov/data/schema.json
+++ b/src/showcov/data/schema.json
@@ -9,6 +9,17 @@
       "type": "string",
       "pattern": "^\\d+\\.\\d+\\.\\d+$"
     },
+    "environment": {
+      "description": "Execution environment details.",
+      "type": "object",
+      "properties": {
+        "coverage_xml": {"type": "string"},
+        "context_lines": {"type": "integer", "minimum": 0},
+        "with_code": {"type": "boolean"}
+      },
+      "required": ["coverage_xml", "context_lines", "with_code"],
+      "additionalProperties": false
+    },
     "files": {
       "description": "List of source files with uncovered code sections.",
       "type": "array",
@@ -60,6 +71,7 @@
   },
   "required": [
     "version",
+    "environment",
     "files"
   ],
   "additionalProperties": false
diff --git a/src/showcov/output.py b/src/showcov/output.py
new file mode 100644
index 0000000..5634b2b
--- /dev/null
+++ b/src/showcov/output.py
@@ -0,0 +1,133 @@
+"""Output formatting utilities for showcov."""
+
+from __future__ import annotations
+
+import json
+from importlib import resources
+from pathlib import Path
+from typing import TYPE_CHECKING, Protocol
+
+from colorama import Fore, Style
+from colorama import init as colorama_init
+from jsonschema import validate
+
+from . import __version__
+
+if TYPE_CHECKING:
+    from .core import UncoveredSection
+
+colorama_init(autoreset=True)
+
+# Load JSON schema once
+SCHEMA = json.loads(resources.files("showcov.data").joinpath("schema.json").read_text(encoding="utf-8"))
+
+
+class Formatter(Protocol):
+    def __call__(
+        self,
+        sections: list[UncoveredSection],
+        *,
+        context_lines: int,
+        with_code: bool,
+        coverage_xml: Path,
+        color: bool,
+    ) -> str: ...
+
+
+def _colors(*, enabled: bool) -> dict[str, str]:
+    if not enabled:
+        return {"RESET": "", "BOLD": "", "YELLOW": "", "CYAN": "", "MAGENTA": "", "GREEN": "", "RED": ""}
+    return {
+        "RESET": Style.RESET_ALL,
+        "BOLD": Style.BRIGHT,
+        "YELLOW": Fore.YELLOW,
+        "CYAN": Fore.CYAN,
+        "MAGENTA": Fore.MAGENTA,
+        "GREEN": Fore.GREEN,
+        "RED": Fore.RED,
+    }
+
+
+def format_human(
+    sections: list[UncoveredSection],
+    *,
+    context_lines: int,
+    with_code: bool,  # noqa: ARG001 - kept for consistent signature
+    coverage_xml: Path,  # noqa: ARG001
+    color: bool,
+) -> str:
+    colors = _colors(enabled=color)
+    if not sections:
+        return f"{colors['GREEN']}{colors['BOLD']}No uncovered lines found!{colors['RESET']}"
+
+    root = Path.cwd().resolve()
+    parts: list[str] = []
+    for section in sections:
+        try:
+            rel = section.file.resolve().relative_to(root)
+        except ValueError:
+            rel = section.file.resolve()
+        parts.append(
+            f"\n{colors['BOLD']}{colors['YELLOW']}Uncovered sections in {rel.as_posix()}:{colors['RESET']}"
+        )
+        try:
+            with section.file.open(encoding="utf-8") as f:
+                file_lines = [ln.rstrip("\n") for ln in f.readlines()]
+        except OSError:
+            for start, end in section.ranges:
+                text = (
+                    f"  {colors['CYAN']}Lines {start}-{end}{colors['RESET']}"
+                    if start != end
+                    else f"  {colors['CYAN']}Line {start}{colors['RESET']}"
+                )
+                parts.append(text)
+            continue
+        for start, end in section.ranges:
+            header = (
+                f"  {colors['BOLD']}{colors['CYAN']}Lines {start}-{end}:{colors['RESET']}"
+                if start != end
+                else f"  {colors['BOLD']}{colors['CYAN']}Line {start}:{colors['RESET']}"
+            )
+            parts.append(header)
+            start_idx = max(1, start - context_lines)
+            end_idx = min(len(file_lines), end + context_lines)
+            for ln in range(start_idx, end_idx + 1):
+                content = file_lines[ln - 1] if 1 <= ln <= len(file_lines) else "<line not found>"
+                if start <= ln <= end:
+                    parts.append(f"    {colors['MAGENTA']}{ln:4d}{colors['RESET']}: {content}")
+                else:
+                    parts.append(f"    {ln:4d}: {content}")
+            parts.append("")
+    return "\n".join(parts).lstrip("\n")
+
+
+def format_json(
+    sections: list[UncoveredSection],
+    *,
+    context_lines: int,
+    with_code: bool,
+    coverage_xml: Path,
+    color: bool,  # noqa: ARG001
+) -> str:
+    root = Path.cwd().resolve()
+    try:
+        xml_path = coverage_xml.resolve().relative_to(root)
+    except ValueError:
+        xml_path = coverage_xml.resolve()
+    data: dict[str, object] = {
+        "version": __version__,
+        "environment": {
+            "coverage_xml": xml_path.as_posix(),
+            "context_lines": context_lines,
+            "with_code": with_code,
+        },
+        "files": [sec.to_dict(with_code=with_code, context_lines=context_lines) for sec in sections],
+    }
+    validate(data, SCHEMA)
+    return json.dumps(data, indent=2, sort_keys=True)
+
+
+FORMATTERS: dict[str, Formatter] = {
+    "human": format_human,
+    "json": format_json,
+}
diff --git a/tests/test_cli.py b/tests/test_cli.py
index 7779f58..7719336 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -9,18 +9,25 @@ from _pytest.monkeypatch import MonkeyPatch
 from jsonschema import ValidationError, validate
 
 from showcov import __version__
-from showcov.cli import main, print_json_output
+from showcov.cli import main
 from showcov.core import build_sections
+from showcov.output import format_json
 
 
-def test_print_json_output(tmp_path: Path, capsys: CaptureFixture) -> None:
+def test_format_json_output(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("print('hi')\n")
     sections = build_sections({source_file: [1, 2, 4]})
-    print_json_output(sections, with_code=False, context_lines=0)
-    captured = capsys.readouterr().out
-    assert "\x1b" not in captured
-    data = json.loads(captured)
+    out = format_json(
+        sections,
+        with_code=False,
+        context_lines=0,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    assert "\x1b" not in out
+    data = json.loads(out)
+    assert data["environment"]["coverage_xml"] == (tmp_path / "cov.xml").resolve().as_posix()
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [
         {"start": 1, "end": 2},
@@ -53,6 +60,7 @@ def test_main_json_output(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: Capt
     captured = capsys.readouterr().out
     assert "\x1b" not in captured
     data = json.loads(captured)
+    assert data["environment"]["coverage_xml"] == xml_file.resolve().as_posix()
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [{"start": 1, "end": 1}]
 
@@ -81,15 +89,22 @@ def test_main_json_output_no_uncovered(
     main()
     captured = capsys.readouterr().out
     data = json.loads(captured)
+    assert data["environment"]["coverage_xml"] == xml_file.resolve().as_posix()
     assert data["files"] == []
 
 
-def test_print_json_output_with_code_and_context(tmp_path: Path, capsys: CaptureFixture) -> None:
+def test_format_json_output_with_code_and_context(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("a\nb\nc\n")
     sections = build_sections({source_file: [2]})
-    print_json_output(sections, with_code=True, context_lines=1)
-    data = json.loads(capsys.readouterr().out)
+    out = format_json(
+        sections,
+        with_code=True,
+        context_lines=1,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    data = json.loads(out)
     assert data["files"][0]["uncovered"][0]["lines"] == ["a", "b", "c"]
 
 
@@ -97,8 +112,14 @@ def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("print('hi')\n")
     sections = build_sections({source_file: [1]})
-    print_json_output(sections, with_code=True, context_lines=0)
-    data = json.loads(capsys.readouterr().out)
+    out = format_json(
+        sections,
+        with_code=True,
+        context_lines=0,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    data = json.loads(out)
     schema = json.loads(resources.files("showcov.data").joinpath("schema.json").read_text(encoding="utf-8"))
     validate(data, schema)
     bad = {"version": __version__, "files": [{"file": "x", "uncovered": [{"start": "a", "end": 2}]}]}
@@ -106,13 +127,17 @@ def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
         validate(bad, schema)
 
 
-def test_print_json_output_relative_path(
-    tmp_path: Path, capsys: CaptureFixture, monkeypatch: MonkeyPatch
-) -> None:
+def test_format_json_output_relative_path(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:
     monkeypatch.chdir(tmp_path)
     source_file = Path("dummy.py")
     source_file.write_text("print('hi')\n", encoding="utf-8")
     sections = build_sections({source_file: [1]})
-    print_json_output(sections, with_code=False, context_lines=0)
-    data = json.loads(capsys.readouterr().out)
+    out = format_json(
+        sections,
+        with_code=False,
+        context_lines=0,
+        coverage_xml=Path("cov.xml"),
+        color=True,
+    )
+    data = json.loads(out)
     assert data["files"][0]["file"] == "dummy.py"
diff --git a/tests/test_core.py b/tests/test_core.py
index 90f9815..4dee0ee 100644
--- a/tests/test_core.py
+++ b/tests/test_core.py
@@ -10,12 +10,8 @@ from _pytest.capture import CaptureFixture
 from _pytest.monkeypatch import MonkeyPatch
 from defusedxml import ElementTree
 
-from showcov.cli import (
-    disable_colors,
-    main,
-    parse_args,
-    print_uncovered_sections,
-)
+from showcov.cli import main, parse_args
+from showcov.output import format_human
 
 # Import functions and exceptions from your module.
 from showcov.core import (
@@ -128,39 +124,53 @@ def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
 # --- Tests for `print_uncovered_sections` ---
 
 
-def test_print_uncovered_sections(tmp_path: Path, capsys: CaptureFixture) -> None:
+def test_format_human(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("def foo():\n    pass\n\ndef bar():\n    return 42")
     sections = build_sections({source_file: [2, 4, 5]})
-    print_uncovered_sections(sections, context_lines=0)
-    captured = capsys.readouterr().out
-    assert "Uncovered sections in" in captured
-    assert "Line" in captured
-    assert "2" in captured
-    assert "4" in captured
-    assert "5" in captured
-
-
-def test_print_uncovered_sections_no_color(tmp_path: Path, capsys: CaptureFixture) -> None:
+    out = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    assert "Uncovered sections in" in out
+    assert "Line" in out
+    assert "2" in out
+    assert "4" in out
+    assert "5" in out
+
+
+def test_format_human_no_color(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("print('hi')\n")
     sections = build_sections({source_file: [1]})
-    disable_colors()
-    print_uncovered_sections(sections, context_lines=0)
-    captured = capsys.readouterr().out
-    assert "\x1b" not in captured
+    out = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=False,
+    )
+    assert "\x1b" not in out
 
 
-def test_print_uncovered_sections_sorted_files(tmp_path: Path, capsys: CaptureFixture) -> None:
+def test_format_human_sorted_files(tmp_path: Path) -> None:
     file_b = tmp_path / "b.py"
     file_a = tmp_path / "a.py"
     file_a.write_text("a=1\n")
     file_b.write_text("b=1\n")
     sections = build_sections({file_b: [1], file_a: [1]})
-    print_uncovered_sections(sections, context_lines=0)
-    captured = capsys.readouterr().out
-    first = captured.find(file_a.as_posix())
-    second = captured.find(file_b.as_posix())
+    out = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    first = out.find(file_a.as_posix())
+    second = out.find(file_b.as_posix())
     assert first < second
 
 
@@ -388,13 +398,18 @@ def test_merge_blank_gap_groups_no_merge():
 # --- Test for print_uncovered_sections exception branch (lines 163-166, 171) ---
 
 
-def test_print_uncovered_sections_file_open_error(capsys, tmp_path):
+def test_format_human_file_open_error(tmp_path: Path) -> None:
     fake_file = tmp_path / "nonexistent.py"
     sections = build_sections({fake_file: [1, 2]})
-    print_uncovered_sections(sections, context_lines=0)
-    captured = capsys.readouterr().out
-    assert "Uncovered sections in" in captured
-    assert "Line" in captured
+    out = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    assert "Uncovered sections in" in out
+    assert "Line" in out
 
 
 # --- Test for parse_large_xml fallback (line 218) ---
diff --git a/tests/test_output.py b/tests/test_output.py
new file mode 100644
index 0000000..7c84f7e
--- /dev/null
+++ b/tests/test_output.py
@@ -0,0 +1,30 @@
+from pathlib import Path
+
+from showcov.core import build_sections
+from showcov.output import FORMATTERS, format_human
+
+
+def test_format_human_respects_color(tmp_path: Path) -> None:
+    src = tmp_path / "x.py"
+    src.write_text("a\n")
+    sections = build_sections({src: [1]})
+    colored = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=True,
+    )
+    plain = format_human(
+        sections,
+        context_lines=0,
+        with_code=False,
+        coverage_xml=tmp_path / "cov.xml",
+        color=False,
+    )
+    assert "\x1b" in colored
+    assert "\x1b" not in plain
+
+
+def test_format_registry() -> None:
+    assert set(FORMATTERS) == {"human", "json"}

2853c68e8dfe49e7aa18b13a22b5beffee4fe9b5 2025-08-02T13:09:32-04:00
d9dd4d52fa9f16cfe58a11c6c80288df752b7a17 2025-08-02T13:43:14-04:00---
 AGENTS.md | 188 ++++++++++++++++++++++++++++++++++++++++++++++++--------------
 1 file changed, 146 insertions(+), 42 deletions(-)

diff --git a/AGENTS.md b/AGENTS.md
index 76ee673..6e2de41 100644
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -1,75 +1,179 @@
+# AGENTS.md
+
 ## Purpose
 
-This file defines how coding agents (LLMs, autonomous dev tools, etc.) should operate when contributing to this project.
+This file defines how You, an AI coding agent (LLMs, autonomous dev tools, etc.), must operate when contributing to this project.
+
+## Project Context
+
+You are contributing to `showcov`, a CLI tool that identifies uncovered lines in Python source files from a coverage XML report.
 
 ## Role
 
-You are an assistant contributing to `showcov`, a CLI tool that identifies uncovered lines in Python source files from a coverage XML report.
 
 Your responsibilities include:
-- Editing Python source files under `src/showcov/`
-- Editing or creating test files under `tests/`
-- Maintaining output determinism, testability, and format extensibility
-- Respecting existing CLI design and internal architecture
 
-## Directories
+* Editing Python source files under `src/showcov/`
+* Creating or editing test files under `tests/`
+* Preserving output determinism, testability, and extensibility
+* Respecting existing CLI conventions and internal architecture
+
+## Directory Constraints
+
+
 
-- Source code: `src/showcov/`
-- Tests: `tests/`
-- Do not create or modify files outside these directories unless explicitly instructed.
+* Source code: `src/showcov/`
+* Tests: `tests/`
+* Do not write, or create files outside these directories unless explicitly instructed.
 
 ## Tooling Requirements
 
-You must use the following tools for validation and conformance before proposing code:
+Before proposing code, validate all changes using the tools below.
+
+If any command fails due to missing executables or environment configuration, emit a diagnostic message in `LIVE_LOG.md` and request clarification from the user.
 
 ### Linting
-- Run: `ruff check src/ tests/`
-- Use rules defined in `pyproject.toml` and any referenced `ruff.default.toml`
+
+* Command: `.venv/bin/ruff check src/ tests/`
+* Rules: Defined in `pyproject.toml` and any referenced config files
 
 ### Formatting
-- Run: `ruff format src/ tests/`
+
+* Command: `.venv/bin/ruff format src/ tests/`
 
 ### Static Typing
-- Run: `ty check src/ tests/`
-- Use Python 3.13–compatible type syntax.
-- Respect constraints in `pyproject.toml`
+
+* Command: `.venv/bin/ty check src/ tests/`
+* Syntax: Use Python 3.13–compatible type annotations
+* Constraints: Must follow `pyproject.toml` settings
+
+> If `ty` is not available in `.venv/bin/`, log a failure notice in `LIVE_LOG.md`, emit proposed code as a Markdown patch, and halt execution.
 
 ### Testing
-- Run: `pytest`
-- `pytest` should follow the settings in `pyproject.toml`
-- Add test coverage for new features or regression paths.
-- Use deterministic test data and avoid system-dependent values (e.g., timestamps, absolute paths).
+
+* Command: `.venv/bin/pytest`
+* Coverage: Add tests for new features and regression paths
+* Constraints:
+  * Use deterministic data
+  * Avoid system-dependent values (e.g., timestamps, user paths)
+  * Use `.venv/bin/pytest` to generate coverage
+
+> If coverage decreases from the baseline in `coverage.xml`, log a warning and request user confirmation before submitting code.
 
 ## Behavior Constraints
 
-- **Path normalization**: always use POSIX-style (`/`) paths in output and JSON.
-- **Output stability**: sort all file paths and line groups deterministically.
-- **No ANSI styling** in non-human formats (e.g., JSON).
-- **No I/O outside of `src/`, `tests/`, or `TODO.md`** unless instructed.
-- **Maintain Code Quality During Development**: run linter, formatter, and type checker after editing code.
-- **Keep the User Updated**: While performing edits, if you have chat capability, write out status updates prefixed with "WORK STATUS: "
-- **Keep to do list up to date**: as items on the TODO.md list are finished, mark them as complete.
+* Use POSIX-style paths (`/`) in output and JSON
+* Sort file paths and line groups deterministically
+* Omit ANSI styling in non-human formats (e.g., JSON)
+* No I/O outside `src/`, `tests/`, or `TODO.md` unless instructed
+* Maintain internal consistency across toolchain and file states
+
+## Logging and Progress Tracking
+
+### Live Log
+
+
+Maintain a `LIVE_LOG.md` file at the project root.
+Each entry must:
+
+* Be timestamped (`YYYY-MM-DDTHH:MMZ`) in ISO8601 format
+* Use readable Markdown headings and bullet points
+* Record major actions, decisions, errors, and state changes
+
+Example:
+
+```markdown
+## 2025-08-02T14:20Z
+
+- ran `.venv/bin/ruff check` with 0 errors
+- static typing failed: `ty` not found in `.venv/bin/`
+- emitted patch instead of direct code write
+````
+
+### To-Do List Maintenance
+
+* As you complete items from `TODO.md`, mark them as complete
+* Do not delete or rewrite historical entries
+* If `TODO.md` is missing, create a new file and notify the user in `LIVE_LOG.md`
+
+## Changelog Maintenance
+
+
+Follow [Keep a Changelog](https://keepachangelog.com/en/1.1.0/) format:
+
+* Example heading: `## [1.2.3] - 2025-08-02`
+* Allowed sections: `Added`, `Changed`, `Deprecated`, `Removed`, `Fixed`, `Security`
+* Each bullet must:
+
+  * Begin with a lowercase imperative verb (e.g., “add”, “fix”)
+  * Follow Markdown syntax
+
+Ensure:
+
+* Changelog matches the actual code changes
+* Version in `pyproject.toml` is updated
+* Historical entries are never modified
+* If `CHANGELOG.md` is missing, create a stub file and note this in `LIVE_LOG.md`
+
+Example:
+
+```markdown
+## [1.4.0] - 2025-08-02
+
+### Added
+- add `--format json` CLI option for machine-readable output
+
+### Fixed
+- fix incorrect grouping of adjacent blank lines in coverage reports
+```
 
 ## Commit Standards
 
-- Each commit should pass:  
-  - `ruff check && ruff format`  
-  - `ty check`  
-  - `pytest`
+Each commit must pass:
 
-- Prefer conventional commit messages:
-  - `feat: add --format json`
-  - `fix: handle missing <class> tag in coverage XML`
-  - `test: add tests for merge_blank_gap_groups`
+* `.venv/bin/ruff check && .venv/bin/ruff format`
+* `.venv/bin/ty check`
+* `.venv/bin/pytest`
 
-- Bump the version in `pyproject.toml` as appropriate before pull requests.
+Use conventional commit messages:
 
-## Prohibited
+* `feat: add --format json`
+* `fix: handle missing <class> tag in coverage XML`
+* `test: add tests for merge_blank_gap_groups`
 
-- Do not introduce new dependencies without justification in a comment.
-- Do not remove test coverage.
-- Do not introduce non-deterministic behavior.
+Before submitting a pull request:
+
+* Bump the version in `pyproject.toml` if relevant
+* Update `CHANGELOG.md` accordingly
+
+## Prohibited Behavior
+
+* Do not add new dependencies without an inline comment justifying the change
+* Do not reduce test coverage unless explicitly approved
+* Do not introduce non-determinism (e.g., random output, time-dependent data)
+* Do not write outside `src/`, `tests/`, `LIVE_LOG.md`, `CHANGELOG.md`, or `TODO.md` unless instructed
+
+## Assumptions and Capabilities
+
+You must assume:
+
+* No access to long-term memory
+* Each task starts with only the current file state
+* You must re-read `LIVE_LOG.md`, `TODO.md`, and `CHANGELOG.md` before taking action on historical items
+
+If lacking access to shell or file I/O:
+
+* Emit a Markdown-formatted patch containing proposed edits
+* Describe expected outputs of toolchain commands
+* Wait for user confirmation before proceeding
 
 ## Compliance
 
-All contributions must adhere to this protocol unless overridden by a specific user instruction or documented exception.
+All actions must follow this protocol unless:
+
+* Overridden by an explicit user instruction
+* Covered by a documented exception in this file
+
+```
+```
+

828e56e6d6f3f466532c6071415652fc63880efe 2025-08-02T13:44:56-04:00---
 TODO.md | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/TODO.md b/TODO.md
index c8eeeec..c576a22 100644
--- a/TODO.md
+++ b/TODO.md
@@ -44,7 +44,7 @@
 
 ### Phase 5: Protocol/tooling Integration Readiness
 
-* [ ] Ensure output JSON is valid with `application/json` MIME type, no extra preamble or wrapper.
-* [ ] Expose main logic as a function callable via API: `get_coverage_data(xml_path: Path) -> list[UncoveredSection]` (already done but ensure documentation and tests).
-* [ ] Annotate output functions with complete type hints using `TypedDict` or `pydantic.BaseModel`.
+* [x] Ensure output JSON is valid with `application/json` MIME type, no extra preamble or wrapper.
+* [x] Expose main logic as a function callable via API: `get_coverage_data(xml_path: Path) -> list[UncoveredSection]` (already done but ensure documentation and tests).
+* [x] Annotate output functions with complete type hints using `TypedDict` or `pydantic.BaseModel`.
 * [ ] Ensure public API and output are documented for CLI/API parity and external tooling consumption.

f91f9b6af0149cc52db7674d96c67546a28cd2a8 2025-08-02T13:46:50-04:00---
 AGENTS.md    | 14 +++++++-------
 CHANGELOG.md |  0
 LIVELOG.md   |  0
 3 files changed, 7 insertions(+), 7 deletions(-)

diff --git a/AGENTS.md b/AGENTS.md
index 6e2de41..9e0410c 100644
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -30,7 +30,7 @@ Your responsibilities include:
 
 Before proposing code, validate all changes using the tools below.
 
-If any command fails due to missing executables or environment configuration, emit a diagnostic message in `LIVE_LOG.md` and request clarification from the user.
+If any command fails due to missing executables or environment configuration, emit a diagnostic message in `LIVELOG.md` and request clarification from the user.
 
 ### Linting
 
@@ -47,7 +47,7 @@ If any command fails due to missing executables or environment configuration, em
 * Syntax: Use Python 3.13–compatible type annotations
 * Constraints: Must follow `pyproject.toml` settings
 
-> If `ty` is not available in `.venv/bin/`, log a failure notice in `LIVE_LOG.md`, emit proposed code as a Markdown patch, and halt execution.
+> If `ty` is not available in `.venv/bin/`, log a failure notice in `LIVELOG.md`, emit proposed code as a Markdown patch, and halt execution.
 
 ### Testing
 
@@ -73,7 +73,7 @@ If any command fails due to missing executables or environment configuration, em
 ### Live Log
 
 
-Maintain a `LIVE_LOG.md` file at the project root.
+Maintain a `LIVELOG.md` file at the project root.
 Each entry must:
 
 * Be timestamped (`YYYY-MM-DDTHH:MMZ`) in ISO8601 format
@@ -94,7 +94,7 @@ Example:
 
 * As you complete items from `TODO.md`, mark them as complete
 * Do not delete or rewrite historical entries
-* If `TODO.md` is missing, create a new file and notify the user in `LIVE_LOG.md`
+* If `TODO.md` is missing, create a new file and notify the user in `LIVELOG.md`
 
 ## Changelog Maintenance
 
@@ -113,7 +113,7 @@ Ensure:
 * Changelog matches the actual code changes
 * Version in `pyproject.toml` is updated
 * Historical entries are never modified
-* If `CHANGELOG.md` is missing, create a stub file and note this in `LIVE_LOG.md`
+* If `CHANGELOG.md` is missing, create a stub file and note this in `LIVELOG.md`
 
 Example:
 
@@ -151,7 +151,7 @@ Before submitting a pull request:
 * Do not add new dependencies without an inline comment justifying the change
 * Do not reduce test coverage unless explicitly approved
 * Do not introduce non-determinism (e.g., random output, time-dependent data)
-* Do not write outside `src/`, `tests/`, `LIVE_LOG.md`, `CHANGELOG.md`, or `TODO.md` unless instructed
+* Do not write outside `src/`, `tests/`, `LIVELOG.md`, `CHANGELOG.md`, or `TODO.md` unless instructed
 
 ## Assumptions and Capabilities
 
@@ -159,7 +159,7 @@ You must assume:
 
 * No access to long-term memory
 * Each task starts with only the current file state
-* You must re-read `LIVE_LOG.md`, `TODO.md`, and `CHANGELOG.md` before taking action on historical items
+* You must re-read `LIVELOG.md`, `TODO.md`, and `CHANGELOG.md` before taking action on historical items
 
 If lacking access to shell or file I/O:
 
diff --git a/CHANGELOG.md b/CHANGELOG.md
new file mode 100644
index 0000000..e69de29
diff --git a/LIVELOG.md b/LIVELOG.md
new file mode 100644
index 0000000..e69de29

c84f96665293c9be5d55c57656946705fa4fca43 2025-08-02T13:53:44-04:00---
 CHANGELOG.md                 |  8 +++++
 LIVELOG.md                   |  7 ++++
 TODO.md                      |  8 ++---
 pyproject.toml               |  2 +-
 src/showcov/cli.py           |  6 ++--
 src/showcov/core.py          | 21 ++++++-----
 src/showcov/data/schema.json | 14 +++++---
 src/showcov/output.py        | 10 +++---
 tests/test_cli.py            | 84 +++++++++++++++++++++++++++++++++++++++-----
 tests/test_core.py           | 21 ++++++++---
 tests/test_output.py         |  4 +--
 11 files changed, 143 insertions(+), 42 deletions(-)

diff --git a/CHANGELOG.md b/CHANGELOG.md
index e69de29..360d209 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -0,0 +1,8 @@
+## [0.0.5] - 2025-08-02
+
+### Added
+- add `--embed-source` flag to embed raw source lines with line numbers in JSON output
+- embed source data using machine-friendly structure for LLM tooling
+
+### Fixed
+- remove system-dependent fields from JSON environment metadata
diff --git a/LIVELOG.md b/LIVELOG.md
index e69de29..0678990 100644
--- a/LIVELOG.md
+++ b/LIVELOG.md
@@ -0,0 +1,7 @@
+## 2025-08-02T17:51Z
+- start implementing Phase 3 tasks: add `--embed-source` option and machine-friendly JSON
+## 2025-08-02T17:52Z
+- ran `.venv/bin/ruff format src/ tests/`
+- ran `.venv/bin/ruff check src/ tests/`
+- ran `.venv/bin/ty check src/ tests/`
+- ran `.venv/bin/pytest`
diff --git a/TODO.md b/TODO.md
index c576a22..55ab4c8 100644
--- a/TODO.md
+++ b/TODO.md
@@ -30,11 +30,11 @@
 
 ### Phase 3: Feature Completion and Determinism Guarantees (LLM Usability focus)
 
-* [ ] Add option `--embed-source` to include raw source lines under each uncovered range.
-* [ ] Avoid floating or system-dependent fields (timestamps, random hashes, etc.) in all outputs.
+* [x] Add option `--embed-source` to include raw source lines under each uncovered range.
+* [x] Avoid floating or system-dependent fields (timestamps, random hashes, etc.) in all outputs.
 * [x] Ensure stable sorting: files alphabetically by posix path, uncovered groups ordered numerically, as invariants.
-* [ ] Ensure all JSON output fully complies with machine-friendly constraints (no ANSI in non-human modes, consistent structure).
-* [ ] Design output to conform to emerging context-tool protocols (e.g. OpenAI tool-calling, LangChain toolkits) as needed.
+* [x] Ensure all JSON output fully complies with machine-friendly constraints (no ANSI in non-human modes, consistent structure).
+* [x] Design output to conform to emerging context-tool protocols (e.g. OpenAI tool-calling, LangChain toolkits) as needed.
 
 ### Phase 4: Testing Enhancements beyond Basic Correctness
 
diff --git a/pyproject.toml b/pyproject.toml
index 5698dd3..138a902 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,7 +1,7 @@
 # =================================== project ====================================
 [project]
   name = "showcov"
-  version = "0.0.4"
+  version = "0.0.5"
   description = "Print out uncovered code."
   readme = "README.md"
   authors = [
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
index 7419a43..d048fd1 100644
--- a/src/showcov/cli.py
+++ b/src/showcov/cli.py
@@ -33,9 +33,9 @@ def parse_args() -> argparse.Namespace:
         help="Disable ANSI color codes in output",
     )
     parser.add_argument(
-        "--with-code",
+        "--embed-source",
         action="store_true",
-        help="Include source code lines in JSON output",
+        help="Embed raw source lines for uncovered ranges in JSON output",
     )
     parser.add_argument(
         "--context-lines",
@@ -79,7 +79,7 @@ def main() -> None:
     output = formatter(
         sections,
         context_lines=args.context_lines,
-        with_code=args.with_code,
+        embed_source=args.embed_source,
         coverage_xml=xml_file,
         color=not args.no_color,
     )
diff --git a/src/showcov/core.py b/src/showcov/core.py
index 272e13a..05ba22c 100644
--- a/src/showcov/core.py
+++ b/src/showcov/core.py
@@ -48,18 +48,18 @@ class UncoveredSection:
     file: Path
     ranges: list[tuple[int, int]]
 
-    def to_dict(self, *, with_code: bool = False, context_lines: int = 0) -> dict[str, object]:
+    def to_dict(self, *, embed_source: bool = False, context_lines: int = 0) -> dict[str, object]:
         """Convert the section into a JSON-serialisable dictionary.
 
         Parameters
         ----------
-        with_code:
-            Include source code lines within each uncovered range. When
+        embed_source:
+            Include raw source lines within each uncovered range. When
             ``context_lines`` is greater than zero, the returned lines will
             also include that many lines of surrounding context.
         context_lines:
             Number of context lines to include before and after each uncovered
-            range when ``with_code`` is ``True``.
+            range when ``embed_source`` is ``True``.
         """
         root = Path.cwd().resolve()
         try:
@@ -71,7 +71,7 @@ class UncoveredSection:
         uncovered_entries: list[dict[str, object]] = []
 
         file_lines: list[str] = []
-        if with_code:
+        if embed_source:
             try:
                 with self.file.open(encoding="utf-8") as f:
                     file_lines = [ln.rstrip("\n") for ln in f.readlines()]
@@ -80,14 +80,17 @@ class UncoveredSection:
 
         for start, end in self.ranges:
             entry: dict[str, object] = {"start": start, "end": end}
-            if with_code and file_lines:
+            if embed_source and file_lines:
                 start_idx = max(1, start - context_lines)
                 end_idx = min(len(file_lines), end + context_lines)
-                lines = [
-                    file_lines[i - 1] if 1 <= i <= len(file_lines) else "<line not found>"
+                source = [
+                    {
+                        "line": i,
+                        "code": file_lines[i - 1] if 1 <= i <= len(file_lines) else "<line not found>",
+                    }
                     for i in range(start_idx, end_idx + 1)
                 ]
-                entry["lines"] = lines
+                entry["source"] = source
             uncovered_entries.append(entry)
 
         return {"file": file_str, "uncovered": uncovered_entries}
diff --git a/src/showcov/data/schema.json b/src/showcov/data/schema.json
index db49e33..4c9722c 100644
--- a/src/showcov/data/schema.json
+++ b/src/showcov/data/schema.json
@@ -15,9 +15,9 @@
       "properties": {
         "coverage_xml": {"type": "string"},
         "context_lines": {"type": "integer", "minimum": 0},
-        "with_code": {"type": "boolean"}
+        "embed_source": {"type": "boolean"}
       },
-      "required": ["coverage_xml", "context_lines", "with_code"],
+      "required": ["coverage_xml", "context_lines", "embed_source"],
       "additionalProperties": false
     },
     "files": {
@@ -44,11 +44,17 @@
                   "type": "integer",
                   "minimum": 1
                 },
-                "lines": {
+                "source": {
                   "description": "Optional source code lines in this range.",
                   "type": "array",
                   "items": {
-                    "type": "string"
+                    "type": "object",
+                    "properties": {
+                      "line": {"type": "integer", "minimum": 1},
+                      "code": {"type": "string"}
+                    },
+                    "required": ["line", "code"],
+                    "additionalProperties": false
                   },
                   "minItems": 1
                 }
diff --git a/src/showcov/output.py b/src/showcov/output.py
index 5634b2b..de8b337 100644
--- a/src/showcov/output.py
+++ b/src/showcov/output.py
@@ -28,7 +28,7 @@ class Formatter(Protocol):
         sections: list[UncoveredSection],
         *,
         context_lines: int,
-        with_code: bool,
+        embed_source: bool,
         coverage_xml: Path,
         color: bool,
     ) -> str: ...
@@ -52,7 +52,7 @@ def format_human(
     sections: list[UncoveredSection],
     *,
     context_lines: int,
-    with_code: bool,  # noqa: ARG001 - kept for consistent signature
+    embed_source: bool,  # noqa: ARG001 - kept for consistent signature
     coverage_xml: Path,  # noqa: ARG001
     color: bool,
 ) -> str:
@@ -105,7 +105,7 @@ def format_json(
     sections: list[UncoveredSection],
     *,
     context_lines: int,
-    with_code: bool,
+    embed_source: bool,
     coverage_xml: Path,
     color: bool,  # noqa: ARG001
 ) -> str:
@@ -119,9 +119,9 @@ def format_json(
         "environment": {
             "coverage_xml": xml_path.as_posix(),
             "context_lines": context_lines,
-            "with_code": with_code,
+            "embed_source": embed_source,
         },
-        "files": [sec.to_dict(with_code=with_code, context_lines=context_lines) for sec in sections],
+        "files": [sec.to_dict(embed_source=embed_source, context_lines=context_lines) for sec in sections],
     }
     validate(data, SCHEMA)
     return json.dumps(data, indent=2, sort_keys=True)
diff --git a/tests/test_cli.py b/tests/test_cli.py
index 7719336..0be9790 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -20,14 +20,18 @@ def test_format_json_output(tmp_path: Path) -> None:
     sections = build_sections({source_file: [1, 2, 4]})
     out = format_json(
         sections,
-        with_code=False,
+        embed_source=False,
         context_lines=0,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
     assert "\x1b" not in out
     data = json.loads(out)
-    assert data["environment"]["coverage_xml"] == (tmp_path / "cov.xml").resolve().as_posix()
+    assert data["environment"] == {
+        "coverage_xml": (tmp_path / "cov.xml").resolve().as_posix(),
+        "context_lines": 0,
+        "embed_source": False,
+    }
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [
         {"start": 1, "end": 2},
@@ -60,7 +64,11 @@ def test_main_json_output(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: Capt
     captured = capsys.readouterr().out
     assert "\x1b" not in captured
     data = json.loads(captured)
-    assert data["environment"]["coverage_xml"] == xml_file.resolve().as_posix()
+    assert data["environment"] == {
+        "coverage_xml": xml_file.resolve().as_posix(),
+        "context_lines": 0,
+        "embed_source": False,
+    }
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [{"start": 1, "end": 1}]
 
@@ -89,23 +97,81 @@ def test_main_json_output_no_uncovered(
     main()
     captured = capsys.readouterr().out
     data = json.loads(captured)
-    assert data["environment"]["coverage_xml"] == xml_file.resolve().as_posix()
+    assert data["environment"] == {
+        "coverage_xml": xml_file.resolve().as_posix(),
+        "context_lines": 0,
+        "embed_source": False,
+    }
     assert data["files"] == []
 
 
-def test_format_json_output_with_code_and_context(tmp_path: Path) -> None:
+def test_main_json_output_embed_source(
+    tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture
+) -> None:
+    source_file = tmp_path / "dummy.py"
+    source_file.write_text("a\nb\nc\n")
+    xml_content = f"""
+        <coverage>
+          <packages>
+            <package>
+              <classes>
+                <class filename=\"{source_file}\">
+                  <lines>
+                    <line number=\"2\" hits=\"0\"/>
+                  </lines>
+                </class>
+              </classes>
+            </package>
+          </packages>
+        </coverage>
+    """
+    xml_file = tmp_path / "coverage.xml"
+    xml_file.write_text(xml_content)
+    monkeypatch.setattr(
+        sys,
+        "argv",
+        [
+            "prog",
+            str(xml_file),
+            "--format",
+            "json",
+            "--embed-source",
+            "--context-lines",
+            "1",
+        ],
+    )
+    main()
+    captured = capsys.readouterr().out
+    data = json.loads(captured)
+    assert data["environment"] == {
+        "coverage_xml": xml_file.resolve().as_posix(),
+        "context_lines": 1,
+        "embed_source": True,
+    }
+    assert data["files"][0]["uncovered"][0]["source"] == [
+        {"line": 1, "code": "a"},
+        {"line": 2, "code": "b"},
+        {"line": 3, "code": "c"},
+    ]
+
+
+def test_format_json_output_embed_source_with_context(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("a\nb\nc\n")
     sections = build_sections({source_file: [2]})
     out = format_json(
         sections,
-        with_code=True,
+        embed_source=True,
         context_lines=1,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
     data = json.loads(out)
-    assert data["files"][0]["uncovered"][0]["lines"] == ["a", "b", "c"]
+    assert data["files"][0]["uncovered"][0]["source"] == [
+        {"line": 1, "code": "a"},
+        {"line": 2, "code": "b"},
+        {"line": 3, "code": "c"},
+    ]
 
 
 def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
@@ -114,7 +180,7 @@ def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
     sections = build_sections({source_file: [1]})
     out = format_json(
         sections,
-        with_code=True,
+        embed_source=True,
         context_lines=0,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
@@ -134,7 +200,7 @@ def test_format_json_output_relative_path(tmp_path: Path, monkeypatch: MonkeyPat
     sections = build_sections({source_file: [1]})
     out = format_json(
         sections,
-        with_code=False,
+        embed_source=False,
         context_lines=0,
         coverage_xml=Path("cov.xml"),
         color=True,
diff --git a/tests/test_core.py b/tests/test_core.py
index 4dee0ee..6dd3d23 100644
--- a/tests/test_core.py
+++ b/tests/test_core.py
@@ -11,7 +11,6 @@ from _pytest.monkeypatch import MonkeyPatch
 from defusedxml import ElementTree
 
 from showcov.cli import main, parse_args
-from showcov.output import format_human
 
 # Import functions and exceptions from your module.
 from showcov.core import (
@@ -26,6 +25,7 @@ from showcov.core import (
     merge_blank_gap_groups,
     parse_large_xml,
 )
+from showcov.output import format_human
 
 # Set logging level to capture output for tests
 logging.basicConfig(level=logging.INFO)
@@ -95,6 +95,7 @@ def test_parse_args_no_file(monkeypatch: MonkeyPatch) -> None:
     assert args.xml_file is None
     assert args.no_color is False
     assert args.format == "human"
+    assert args.embed_source is False
 
 
 def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
@@ -104,6 +105,7 @@ def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
     assert args.xml_file == "coverage.xml"
     assert args.no_color is False
     assert args.format == "human"
+    assert args.embed_source is False
 
 
 def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
@@ -112,6 +114,7 @@ def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
     args = parse_args()
     assert args.no_color is True
     assert args.format == "human"
+    assert args.embed_source is False
 
 
 def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
@@ -119,6 +122,14 @@ def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
     assert args.format == "json"
+    assert args.embed_source is False
+
+
+def test_parse_args_embed_source(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "--embed-source"]
+    monkeypatch.setattr(sys, "argv", test_args)
+    args = parse_args()
+    assert args.embed_source is True
 
 
 # --- Tests for `print_uncovered_sections` ---
@@ -131,7 +142,7 @@ def test_format_human(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
@@ -149,7 +160,7 @@ def test_format_human_no_color(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=False,
     )
@@ -165,7 +176,7 @@ def test_format_human_sorted_files(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
@@ -404,7 +415,7 @@ def test_format_human_file_open_error(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
diff --git a/tests/test_output.py b/tests/test_output.py
index 7c84f7e..612def7 100644
--- a/tests/test_output.py
+++ b/tests/test_output.py
@@ -11,14 +11,14 @@ def test_format_human_respects_color(tmp_path: Path) -> None:
     colored = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
     plain = format_human(
         sections,
         context_lines=0,
-        with_code=False,
+        embed_source=False,
         coverage_xml=tmp_path / "cov.xml",
         color=False,
     )

c655779e79aa314f0cabafe5f710f1c626b0264d 2025-08-02T13:54:01-04:00
e6cd2e81b4e2a90b14b80ae7c49661ba2c49fc53 2025-08-02T14:02:23-04:00---
 CHANGELOG.md                 |  2 +-
 LIVELOG.md                   |  2 +-
 TODO.md                      |  3 +--
 src/showcov/cli.py           |  4 ++--
 src/showcov/core.py          | 10 +++++-----
 src/showcov/data/schema.json | 33 ++++++++++++++++++++++++++-------
 src/showcov/output.py        | 10 +++++-----
 tests/test_cli.py            | 24 +++++++++++-------------
 tests/test_core.py           | 22 +++++++++++-----------
 tests/test_output.py         |  4 ++--
 10 files changed, 65 insertions(+), 49 deletions(-)

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 360d209..e368797 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,7 +1,7 @@
 ## [0.0.5] - 2025-08-02
 
 ### Added
-- add `--embed-source` flag to embed raw source lines with line numbers in JSON output
+- add `--with-code` flag to embed raw source lines with line numbers in JSON output
 - embed source data using machine-friendly structure for LLM tooling
 
 ### Fixed
diff --git a/LIVELOG.md b/LIVELOG.md
index 0678990..b811343 100644
--- a/LIVELOG.md
+++ b/LIVELOG.md
@@ -1,5 +1,5 @@
 ## 2025-08-02T17:51Z
-- start implementing Phase 3 tasks: add `--embed-source` option and machine-friendly JSON
+- start implementing Phase 3 tasks: add `--with-code` option and machine-friendly JSON
 ## 2025-08-02T17:52Z
 - ran `.venv/bin/ruff format src/ tests/`
 - ran `.venv/bin/ruff check src/ tests/`
diff --git a/TODO.md b/TODO.md
index 55ab4c8..d45e00c 100644
--- a/TODO.md
+++ b/TODO.md
@@ -13,7 +13,6 @@
 * [x] Update/add tests covering:
 
   * [x] JSON output structure using the model.
-  * [x] Presence/absence of code with `--with-code` and context lines.
   * [x] Schema validation success/failure.
   * [x] No ANSI escape codes in JSON.
   * [x] Stable ordering of files and ranges.
@@ -30,7 +29,7 @@
 
 ### Phase 3: Feature Completion and Determinism Guarantees (LLM Usability focus)
 
-* [x] Add option `--embed-source` to include raw source lines under each uncovered range.
+* [x] Add option `--with-code` to include raw source lines under each uncovered range.
 * [x] Avoid floating or system-dependent fields (timestamps, random hashes, etc.) in all outputs.
 * [x] Ensure stable sorting: files alphabetically by posix path, uncovered groups ordered numerically, as invariants.
 * [x] Ensure all JSON output fully complies with machine-friendly constraints (no ANSI in non-human modes, consistent structure).
diff --git a/src/showcov/cli.py b/src/showcov/cli.py
index d048fd1..58b4ac6 100644
--- a/src/showcov/cli.py
+++ b/src/showcov/cli.py
@@ -33,7 +33,7 @@ def parse_args() -> argparse.Namespace:
         help="Disable ANSI color codes in output",
     )
     parser.add_argument(
-        "--embed-source",
+        "--with-code",
         action="store_true",
         help="Embed raw source lines for uncovered ranges in JSON output",
     )
@@ -79,7 +79,7 @@ def main() -> None:
     output = formatter(
         sections,
         context_lines=args.context_lines,
-        embed_source=args.embed_source,
+        with_code=args.with_code,
         coverage_xml=xml_file,
         color=not args.no_color,
     )
diff --git a/src/showcov/core.py b/src/showcov/core.py
index 05ba22c..f9a616e 100644
--- a/src/showcov/core.py
+++ b/src/showcov/core.py
@@ -48,18 +48,18 @@ class UncoveredSection:
     file: Path
     ranges: list[tuple[int, int]]
 
-    def to_dict(self, *, embed_source: bool = False, context_lines: int = 0) -> dict[str, object]:
+    def to_dict(self, *, with_code: bool = False, context_lines: int = 0) -> dict[str, object]:
         """Convert the section into a JSON-serialisable dictionary.
 
         Parameters
         ----------
-        embed_source:
+        with_code:
             Include raw source lines within each uncovered range. When
             ``context_lines`` is greater than zero, the returned lines will
             also include that many lines of surrounding context.
         context_lines:
             Number of context lines to include before and after each uncovered
-            range when ``embed_source`` is ``True``.
+            range when ``with_code`` is ``True``.
         """
         root = Path.cwd().resolve()
         try:
@@ -71,7 +71,7 @@ class UncoveredSection:
         uncovered_entries: list[dict[str, object]] = []
 
         file_lines: list[str] = []
-        if embed_source:
+        if with_code:
             try:
                 with self.file.open(encoding="utf-8") as f:
                     file_lines = [ln.rstrip("\n") for ln in f.readlines()]
@@ -80,7 +80,7 @@ class UncoveredSection:
 
         for start, end in self.ranges:
             entry: dict[str, object] = {"start": start, "end": end}
-            if embed_source and file_lines:
+            if with_code and file_lines:
                 start_idx = max(1, start - context_lines)
                 end_idx = min(len(file_lines), end + context_lines)
                 source = [
diff --git a/src/showcov/data/schema.json b/src/showcov/data/schema.json
index 4c9722c..eeec237 100644
--- a/src/showcov/data/schema.json
+++ b/src/showcov/data/schema.json
@@ -13,11 +13,22 @@
       "description": "Execution environment details.",
       "type": "object",
       "properties": {
-        "coverage_xml": {"type": "string"},
-        "context_lines": {"type": "integer", "minimum": 0},
-        "embed_source": {"type": "boolean"}
+        "coverage_xml": {
+          "type": "string"
+        },
+        "context_lines": {
+          "type": "integer",
+          "minimum": 0
+        },
+        "with_code": {
+          "type": "boolean"
+        }
       },
-      "required": ["coverage_xml", "context_lines", "embed_source"],
+      "required": [
+        "coverage_xml",
+        "context_lines",
+        "with_code"
+      ],
       "additionalProperties": false
     },
     "files": {
@@ -50,10 +61,18 @@
                   "items": {
                     "type": "object",
                     "properties": {
-                      "line": {"type": "integer", "minimum": 1},
-                      "code": {"type": "string"}
+                      "line": {
+                        "type": "integer",
+                        "minimum": 1
+                      },
+                      "code": {
+                        "type": "string"
+                      }
                     },
-                    "required": ["line", "code"],
+                    "required": [
+                      "line",
+                      "code"
+                    ],
                     "additionalProperties": false
                   },
                   "minItems": 1
diff --git a/src/showcov/output.py b/src/showcov/output.py
index de8b337..5634b2b 100644
--- a/src/showcov/output.py
+++ b/src/showcov/output.py
@@ -28,7 +28,7 @@ class Formatter(Protocol):
         sections: list[UncoveredSection],
         *,
         context_lines: int,
-        embed_source: bool,
+        with_code: bool,
         coverage_xml: Path,
         color: bool,
     ) -> str: ...
@@ -52,7 +52,7 @@ def format_human(
     sections: list[UncoveredSection],
     *,
     context_lines: int,
-    embed_source: bool,  # noqa: ARG001 - kept for consistent signature
+    with_code: bool,  # noqa: ARG001 - kept for consistent signature
     coverage_xml: Path,  # noqa: ARG001
     color: bool,
 ) -> str:
@@ -105,7 +105,7 @@ def format_json(
     sections: list[UncoveredSection],
     *,
     context_lines: int,
-    embed_source: bool,
+    with_code: bool,
     coverage_xml: Path,
     color: bool,  # noqa: ARG001
 ) -> str:
@@ -119,9 +119,9 @@ def format_json(
         "environment": {
             "coverage_xml": xml_path.as_posix(),
             "context_lines": context_lines,
-            "embed_source": embed_source,
+            "with_code": with_code,
         },
-        "files": [sec.to_dict(embed_source=embed_source, context_lines=context_lines) for sec in sections],
+        "files": [sec.to_dict(with_code=with_code, context_lines=context_lines) for sec in sections],
     }
     validate(data, SCHEMA)
     return json.dumps(data, indent=2, sort_keys=True)
diff --git a/tests/test_cli.py b/tests/test_cli.py
index 0be9790..ac2eaa6 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -20,7 +20,7 @@ def test_format_json_output(tmp_path: Path) -> None:
     sections = build_sections({source_file: [1, 2, 4]})
     out = format_json(
         sections,
-        embed_source=False,
+        with_code=False,
         context_lines=0,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
@@ -30,7 +30,7 @@ def test_format_json_output(tmp_path: Path) -> None:
     assert data["environment"] == {
         "coverage_xml": (tmp_path / "cov.xml").resolve().as_posix(),
         "context_lines": 0,
-        "embed_source": False,
+        "with_code": False,
     }
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [
@@ -67,7 +67,7 @@ def test_main_json_output(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: Capt
     assert data["environment"] == {
         "coverage_xml": xml_file.resolve().as_posix(),
         "context_lines": 0,
-        "embed_source": False,
+        "with_code": False,
     }
     assert data["files"][0]["file"] == source_file.resolve().as_posix()
     assert data["files"][0]["uncovered"] == [{"start": 1, "end": 1}]
@@ -100,14 +100,12 @@ def test_main_json_output_no_uncovered(
     assert data["environment"] == {
         "coverage_xml": xml_file.resolve().as_posix(),
         "context_lines": 0,
-        "embed_source": False,
+        "with_code": False,
     }
     assert data["files"] == []
 
 
-def test_main_json_output_embed_source(
-    tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture
-) -> None:
+def test_main_json_output_with_code(tmp_path: Path, monkeypatch: MonkeyPatch, capsys: CaptureFixture) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("a\nb\nc\n")
     xml_content = f"""
@@ -135,7 +133,7 @@ def test_main_json_output_embed_source(
             str(xml_file),
             "--format",
             "json",
-            "--embed-source",
+            "--with-code",
             "--context-lines",
             "1",
         ],
@@ -146,7 +144,7 @@ def test_main_json_output_embed_source(
     assert data["environment"] == {
         "coverage_xml": xml_file.resolve().as_posix(),
         "context_lines": 1,
-        "embed_source": True,
+        "with_code": True,
     }
     assert data["files"][0]["uncovered"][0]["source"] == [
         {"line": 1, "code": "a"},
@@ -155,13 +153,13 @@ def test_main_json_output_embed_source(
     ]
 
 
-def test_format_json_output_embed_source_with_context(tmp_path: Path) -> None:
+def test_format_json_output_with_code_with_context(tmp_path: Path) -> None:
     source_file = tmp_path / "dummy.py"
     source_file.write_text("a\nb\nc\n")
     sections = build_sections({source_file: [2]})
     out = format_json(
         sections,
-        embed_source=True,
+        with_code=True,
         context_lines=1,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
@@ -180,7 +178,7 @@ def test_json_schema_validation(tmp_path: Path, capsys: CaptureFixture) -> None:
     sections = build_sections({source_file: [1]})
     out = format_json(
         sections,
-        embed_source=True,
+        with_code=True,
         context_lines=0,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
@@ -200,7 +198,7 @@ def test_format_json_output_relative_path(tmp_path: Path, monkeypatch: MonkeyPat
     sections = build_sections({source_file: [1]})
     out = format_json(
         sections,
-        embed_source=False,
+        with_code=False,
         context_lines=0,
         coverage_xml=Path("cov.xml"),
         color=True,
diff --git a/tests/test_core.py b/tests/test_core.py
index 6dd3d23..64899c1 100644
--- a/tests/test_core.py
+++ b/tests/test_core.py
@@ -95,7 +95,7 @@ def test_parse_args_no_file(monkeypatch: MonkeyPatch) -> None:
     assert args.xml_file is None
     assert args.no_color is False
     assert args.format == "human"
-    assert args.embed_source is False
+    assert args.with_code is False
 
 
 def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
@@ -105,7 +105,7 @@ def test_parse_args_with_file(monkeypatch: MonkeyPatch) -> None:
     assert args.xml_file == "coverage.xml"
     assert args.no_color is False
     assert args.format == "human"
-    assert args.embed_source is False
+    assert args.with_code is False
 
 
 def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
@@ -114,7 +114,7 @@ def test_parse_args_no_color_flag(monkeypatch: MonkeyPatch) -> None:
     args = parse_args()
     assert args.no_color is True
     assert args.format == "human"
-    assert args.embed_source is False
+    assert args.with_code is False
 
 
 def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
@@ -122,14 +122,14 @@ def test_parse_args_format_json(monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
     assert args.format == "json"
-    assert args.embed_source is False
+    assert args.with_code is False
 
 
-def test_parse_args_embed_source(monkeypatch: MonkeyPatch) -> None:
-    test_args = ["prog", "--embed-source"]
+def test_parse_args_with_code(monkeypatch: MonkeyPatch) -> None:
+    test_args = ["prog", "--with-code"]
     monkeypatch.setattr(sys, "argv", test_args)
     args = parse_args()
-    assert args.embed_source is True
+    assert args.with_code is True
 
 
 # --- Tests for `print_uncovered_sections` ---
@@ -142,7 +142,7 @@ def test_format_human(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
@@ -160,7 +160,7 @@ def test_format_human_no_color(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=False,
     )
@@ -176,7 +176,7 @@ def test_format_human_sorted_files(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
@@ -415,7 +415,7 @@ def test_format_human_file_open_error(tmp_path: Path) -> None:
     out = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
diff --git a/tests/test_output.py b/tests/test_output.py
index 612def7..7c84f7e 100644
--- a/tests/test_output.py
+++ b/tests/test_output.py
@@ -11,14 +11,14 @@ def test_format_human_respects_color(tmp_path: Path) -> None:
     colored = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=True,
     )
     plain = format_human(
         sections,
         context_lines=0,
-        embed_source=False,
+        with_code=False,
         coverage_xml=tmp_path / "cov.xml",
         color=False,
     )
